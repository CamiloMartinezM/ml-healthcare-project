{"cells":[{"cell_type":"markdown","id":"8b16ec0d","metadata":{"id":"8b16ec0d"},"source":["# ML Course 2024 |  Medical Expenses Prediction Challenge\n","\n","This notebook should serve as a starting point to work on the project. Please read the project description first."]},{"cell_type":"markdown","id":"f6a3a951","metadata":{"id":"f6a3a951"},"source":["# Set team ID\n","Important: set your Team ID here. You can find it in CMS."]},{"cell_type":"code","execution_count":225,"id":"b2bdc09f","metadata":{"executionInfo":{"elapsed":377,"status":"ok","timestamp":1716808582700,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"b2bdc09f"},"outputs":[],"source":["team_id = \"18\"  # Our team ID"]},{"cell_type":"markdown","id":"wJs2YvIMvO9Q","metadata":{"id":"wJs2YvIMvO9Q"},"source":["# [Colab only] Connect to your Google Drive"]},{"cell_type":"code","execution_count":226,"id":"SHVae3MHvI9g","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1557,"status":"ok","timestamp":1716808584619,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"SHVae3MHvI9g","outputId":"c13669b0-1bb0-42ac-bdd5-dde5bba2485c"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":227,"id":"UeTBTeKZvr0z","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1716808584620,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"UeTBTeKZvr0z","outputId":"56d405ce-0539-4c9f-e15f-1022eb3c5c7e"},"outputs":[],"source":["# %cd \"/content/drive/MyDrive/path/to/your/project\""]},{"cell_type":"markdown","id":"19af9755","metadata":{"id":"19af9755"},"source":["# Imports"]},{"cell_type":"markdown","id":"UJskkHs1wW6r","metadata":{"id":"UJskkHs1wW6r"},"source":["[Colab only] Note: if you need to install any packages, run a code cell with content `!pip install packagename`"]},{"cell_type":"code","execution_count":228,"id":"b0153603","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716808584620,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"b0153603"},"outputs":[],"source":["import os\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from prettytable import PrettyTable"]},{"cell_type":"markdown","id":"2f5eaed7","metadata":{"id":"2f5eaed7"},"source":["# Load Data\n","\n","In a first step, we load the provided training data from the csv file"]},{"cell_type":"code","execution_count":229,"id":"2fc6b0bb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1300,"status":"ok","timestamp":1716808585916,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"2fc6b0bb","outputId":"98874125-e5d1-463c-9ac9-d8b04976b814"},"outputs":[{"name":"stdout","output_type":"stream","text":["The loaded dataset has 15000 rows and 110 columns\n"]}],"source":["df_train = pd.read_csv('data/train.csv')\n","print(\"The loaded dataset has {} rows and {} columns\".format(df_train.shape[0], df_train.shape[1]))"]},{"cell_type":"code","execution_count":230,"id":"c321d106","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":307},"executionInfo":{"elapsed":566,"status":"ok","timestamp":1716808586474,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"c321d106","outputId":"6628d002-66eb-420d-e59f-0969d59fe13f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>RACE</th>\n","      <th>SEX</th>\n","      <th>PANEL</th>\n","      <th>WEIGHT</th>\n","      <th>STUDENT_STAT</th>\n","      <th>MIL_ACTIV_DUTY</th>\n","      <th>HON_DISCHARGE</th>\n","      <th>HEALTH_STAT</th>\n","      <th>MENTAL_HLTH</th>\n","      <th>CHRON_BRONCH</th>\n","      <th>...</th>\n","      <th>NUM_PRESCR_MEDS</th>\n","      <th>DIFFIC_HEAR</th>\n","      <th>DIFFIC_SEE</th>\n","      <th>SMOK</th>\n","      <th>OVR_FEEL_14</th>\n","      <th>MENTAL_HLTH_SCR</th>\n","      <th>PHY_HLTH_SCR</th>\n","      <th>OVR_FEEL_30</th>\n","      <th>TOT_MED_EXP</th>\n","      <th>UTILIZATION</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Non-White</td>\n","      <td>1</td>\n","      <td>19</td>\n","      <td>7205.036720</td>\n","      <td>-1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>43.82</td>\n","      <td>61.41</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>LOW</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>White</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>5501.113581</td>\n","      <td>-1</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>60.12</td>\n","      <td>54.80</td>\n","      <td>0</td>\n","      <td>240</td>\n","      <td>LOW</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>White</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>16797.708379</td>\n","      <td>-1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>20</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>60.35</td>\n","      <td>30.08</td>\n","      <td>0</td>\n","      <td>791</td>\n","      <td>LOW</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Non-White</td>\n","      <td>2</td>\n","      <td>19</td>\n","      <td>3605.218411</td>\n","      <td>-1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>20</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>58.32</td>\n","      <td>50.22</td>\n","      <td>0</td>\n","      <td>272</td>\n","      <td>LOW</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Non-White</td>\n","      <td>1</td>\n","      <td>19</td>\n","      <td>11223.127404</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>62.39</td>\n","      <td>56.71</td>\n","      <td>0</td>\n","      <td>1264</td>\n","      <td>LOW</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 110 columns</p>\n","</div>"],"text/plain":["        RACE  SEX  PANEL        WEIGHT  STUDENT_STAT  MIL_ACTIV_DUTY  \\\n","0  Non-White    1     19   7205.036720            -1               2   \n","1      White    1     20   5501.113581            -1               4   \n","2      White    1     20  16797.708379            -1               4   \n","3  Non-White    2     19   3605.218411            -1               2   \n","4  Non-White    1     19  11223.127404             1               2   \n","\n","   HON_DISCHARGE  HEALTH_STAT  MENTAL_HLTH  CHRON_BRONCH  ...  \\\n","0              2            2            2             2  ...   \n","1              2            1            1             2  ...   \n","2              1            3            1             2  ...   \n","3              2            3            3             2  ...   \n","4              2            1            2             2  ...   \n","\n","   NUM_PRESCR_MEDS  DIFFIC_HEAR  DIFFIC_SEE  SMOK  OVR_FEEL_14  \\\n","0                0            2           2     2            1   \n","1               12            2           2     2            0   \n","2               20            2           2     2            0   \n","3               20            2           2     2            0   \n","4                3            2           2     2            0   \n","\n","   MENTAL_HLTH_SCR  PHY_HLTH_SCR  OVR_FEEL_30  TOT_MED_EXP  UTILIZATION  \n","0            43.82         61.41            3            0          LOW  \n","1            60.12         54.80            0          240          LOW  \n","2            60.35         30.08            0          791          LOW  \n","3            58.32         50.22            0          272          LOW  \n","4            62.39         56.71            0         1264          LOW  \n","\n","[5 rows x 110 columns]"]},"execution_count":230,"metadata":{},"output_type":"execute_result"}],"source":["df_train.head()"]},{"cell_type":"markdown","id":"9c9633f0","metadata":{"id":"9c9633f0"},"source":["# Data exploration"]},{"cell_type":"code","execution_count":231,"id":"a109e66a","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1716808586474,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"a109e66a","outputId":"4d758a61-6b44-48bf-ce52-3830970e0842"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# TODO: explore the data thoroughly, i.e. look for missing values, plot feature histograms, etc\n","\n","# This is a (rather bad) plot to get you started:\n","plt.hist(df_train['TOT_MED_EXP'])\n","plt.title(\"Total medical expenses (train)\")\n","plt.show()"]},{"cell_type":"code","execution_count":232,"id":"d02db9c4","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Missing values in each column:\n"," Series([], dtype: int64)\n"]}],"source":["# Check for missing values\n","missing_values = df_train.isnull().sum()\n","print(\"Missing values in each column:\\n\", missing_values[missing_values > 0])\n"]},{"cell_type":"code","execution_count":233,"id":"e8d43316","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Categorical Columns and Unique Values:\n","+-------------+-----------------------+\n","| Column Name |     Unique Values     |\n","+-------------+-----------------------+\n","|     RACE    | ['Non-White' 'White'] |\n","| UTILIZATION |     ['LOW' 'HIGH']    |\n","+-------------+-----------------------+\n","Statistics for Numerical Columns:\n","+----------------------+----------------------+----------------------+------+---------------+--------------+---------------+--------------+\n","|     Column Name      |         Mean         |  Standard Deviation  | Min  |      25%      |     50%      |      75%      |     Max      |\n","+----------------------+----------------------+----------------------+------+---------------+--------------+---------------+--------------+\n","|         SEX          |  1.5326666666666666  | 0.49894837961579447  | 1.0  |      1.0      |     2.0      |      2.0      |     2.0      |\n","|        PANEL         |       19.5328        | 0.49893963166935434  | 19.0 |      19.0     |     20.0     |      20.0     |     20.0     |\n","|        WEIGHT        |   9670.9004792494    |  8555.466892942237   | 0.0  | 3956.82735225 | 7304.9283455 | 12745.0048225 | 96471.920237 |\n","|     STUDENT_STAT     | -0.6588666666666667  |  1.0217783440101194  | -9.0 |      -1.0     |     -1.0     |      -1.0     |     3.0      |\n","|    MIL_ACTIV_DUTY    |  2.4795333333333334  |  0.8674279668311917  | -9.0 |      2.0      |     2.0      |      2.0      |     4.0      |\n","|    HON_DISCHARGE     |  1.8932666666666667  |  0.7418297308988129  | -9.0 |      2.0      |     2.0      |      2.0      |     4.0      |\n","|     HEALTH_STAT      |        2.3784        |  1.1120383155633717  | -8.0 |      2.0      |     2.0      |      3.0      |     5.0      |\n","|     MENTAL_HLTH      |  2.1020666666666665  |  1.064639826147497   | -8.0 |      1.0      |     2.0      |      3.0      |     5.0      |\n","|     CHRON_BRONCH     |  1.9602666666666666  | 0.46836867974952895  | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|       JNT_PAIN       |  1.6366666666666667  |  0.7379420885976569  | -8.0 |      1.0      |     2.0      |      2.0      |     2.0      |\n","|        PREGNT        | -0.24806666666666666 |  1.290157831186146   | -9.0 |      -1.0     |     -1.0     |      1.0      |     2.0      |\n","|       WALK_LIM       |  1.8475333333333332  |  0.5462970604480193  | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|      ACTIV_LIM       |        1.8616        |  0.6248771650744551  | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|      SOCIAL_LIM      |  1.9344666666666666  |  0.3412425510602657  | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|      COGNTV_LIM      |  1.9139333333333333  |  0.5645178836123979  | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|       EMPLYMT        |  2.090533333333333   |  1.472168989730367   | -9.0 |      1.0      |     1.0      |      4.0      |     4.0      |\n","|        REGION        |  2.7847333333333335  |  1.0180026281132804  | 1.0  |      2.0      |     3.0      |      4.0      |     4.0      |\n","|     MARITAL_STAT     |        2.7622        |  1.8849282984538511  | 1.0  |      1.0      |     2.0      |      5.0      |     10.0     |\n","|         AGE          |  45.898466666666664  |  17.843465197813355  | 18.0 |      31.0     |     45.0     |      59.0     |     85.0     |\n","|      POVRTY_CAT      |  3.5037333333333334  |  1.4283284182429064  | 1.0  |      3.0      |     4.0      |      5.0      |     5.0      |\n","|      INSUR_COV       |  1.5491333333333333  |  0.727292590724645   | 1.0  |      1.0      |     1.0      |      2.0      |     3.0      |\n","|      TOT_INCOME      |  32012.937733333332  |  35890.55213983432   | 0.0  |     9000.0    |   21755.0    |    42860.0    |   409118.0   |\n","|        BM_IDX        |       28.26568       |  6.714863520361062   | 10.4 |      23.7     |     27.3     |      31.6     |    162.7     |\n","|     MULT_HIGHBP      | -0.31906666666666667 |  1.1780304095956065  | -9.0 |      -1.0     |     -1.0     |      1.0      |     2.0      |\n","|     HOUSEWRK_LIM     | -0.7669333333333334  |  0.8566575665736231  | -8.0 |      -1.0     |     -1.0     |      -1.0     |     2.0      |\n","|      SCHOOL_LIM      |       -0.7476        |  0.9061727116093279  | -8.0 |      -1.0     |     -1.0     |      -1.0     |     2.0      |\n","|   ADV_NO_FAT_FOOD    |        1.3534        |  1.7130978042539837  | -8.0 |      1.0      |     2.0      |      2.0      |     2.0      |\n","|  ADV_EXERCISE_MORE   |  1.3050666666666666  |  1.6390790404662332  | -8.0 |      1.0      |     2.0      |      2.0      |     2.0      |\n","|     ADV_DNTL_CKP     |       -0.9806        | 0.27561211415534054  | -9.0 |      -1.0     |     -1.0     |      -1.0     |     2.0      |\n","|    FREQ_DNTL_CKP     |  2.1117333333333335  |  1.614627758053127   | -8.0 |      1.0      |     2.0      |      3.0      |     4.0      |\n","|   RSN_NO_DNTL_CKP    | -0.5547333333333333  |  5.497546646473707   | -8.0 |      -1.0     |     -1.0     |      -1.0     |     91.0     |\n","|    RSN_NO_MED_CKP    | -0.5804666666666667  |  5.687138825346273   | -1.0 |      -1.0     |     -1.0     |      -1.0     |     91.0     |\n","|      EMPLYR_INS      |        -0.799        |  3.0134373043023195  | -9.0 |      -1.0     |     -1.0     |      1.0      |     2.0      |\n","|      DOC_CK_BP       |  0.6201333333333333  |  1.6872930330583165  | -9.0 |      1.0      |     1.0      |      1.0      |     2.0      |\n","|      TAKE_RISK       |  1.4701333333333333  |  2.3366654266089038  | -9.0 |      1.0      |     1.0      |      3.0      |     5.0      |\n","| NUM_DEP_OUT_REP_UNT  |        -0.934        | 0.45172735564741673  | -8.0 |      -1.0     |     -1.0     |      -1.0     |     7.0      |\n","|    ADV_BOOST_SEAT    | -0.9998666666666667  | 0.016329931618555657 | -1.0 |      -1.0     |     -1.0     |      -1.0     |     1.0      |\n","| WHEN_ADV_BOOST_SEAT  | -0.9997333333333334  | 0.032659863237111314 | -1.0 |      -1.0     |     -1.0     |      -1.0     |     3.0      |\n","|      FEEL_DEPRS      |  3.3703333333333334  |  2.3501109385837573  | -9.0 |      3.0      |     4.0      |      5.0      |     5.0      |\n","|     ADV_NO_SMKG      | -0.7956666666666666  |  1.4198294322195242  | -9.0 |      -1.0     |     -1.0     |      -1.0     |     3.0      |\n","|    AGE_DIAG_ADHD     | -0.9721333333333333  |  0.5815318800466883  | -8.0 |      -1.0     |     -1.0     |      -1.0     |     17.0     |\n","|      CHILD_SUPP      |  149.29513333333333  |  1323.106073503632   | 0.0  |      0.0      |     0.0      |      0.0      |   39208.0    |\n","|      PROB_WKIDS      |       -0.9816        |  0.8325709088645948  | -9.0 |      -1.0     |     -1.0     |      -1.0     |     99.0     |\n","|      PROB_WBHV       |       -0.9804        |  0.8355012731836369  | -9.0 |      -1.0     |     -1.0     |      -1.0     |     99.0     |\n","|     WEAR_SEATBLT     |  1.1582666666666668  |  0.7654567637426317  | -8.0 |      1.0      |     1.0      |      1.0      |     6.0      |\n","|       PUB_ASST       |  30.506533333333334  |  354.7543266348371   | 0.0  |      0.0      |     0.0      |      0.0      |    8549.0    |\n","|       EDU_DEG        |  1.2141333333333333  |  2.537145914115773   | -9.0 |      -1.0     |     1.0      |      3.0      |     7.0      |\n","|     SPOUSE_PRSNT     |        1.5402        | 0.49839795348162497  | 1.0  |      1.0      |     2.0      |      2.0      |     2.0      |\n","|     TAX_FORM_TYP     |       -0.5326        |  7.882056353567675   | -9.0 |      -1.0     |     -1.0     |      1.0      |     91.0     |\n","|   FOOD_STMP_MNTHS    |        0.8496        |  4.421962244299011   | -9.0 |      -1.0     |     -1.0     |      -1.0     |     12.0     |\n","|    FOOD_STMP_VAL     |       42.9168        |  136.3190886756585   | -8.0 |      -1.0     |     -1.0     |      -1.0     |    4500.0    |\n","|   WHEN_ADV_LAP_BLT   | -0.9905333333333334  | 0.16425238956779145  | -1.0 |      -1.0     |     -1.0     |      -1.0     |     3.0      |\n","|       EDU_YRS        |  6.350666666666666   |  7.2940555549466115  | -9.0 |      -1.0     |     8.0      |      13.0     |     17.0     |\n","|   WHEN_LST_ASTHMA    | -0.9491333333333334  | 0.49547514091344824  | -9.0 |      -1.0     |     -1.0     |      -1.0     |     5.0      |\n","|      FAM_INCOME      |  64508.07133333333   |  60018.230574685265  | 0.0  |    22988.0    |   48000.0    |    86912.75   |   521685.0   |\n","|   DELAY_PRESCR_MED   |        1.9178        |  0.5949790696650923  | -9.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|     ADV_LAP_BLT      | -0.9788666666666667  | 0.28312316425417156  | -9.0 |      -1.0     |     -1.0     |      -1.0     |     2.0      |\n","|    ADV_EAT_HLTHY     | -0.9798666666666667  |  0.2622960836623196  | -9.0 |      -1.0     |     -1.0     |      -1.0     |     2.0      |\n","|     DOC_TIM_ALN      | -0.9783333333333334  |  0.287058732207534   | -9.0 |      -1.0     |     -1.0     |      -1.0     |     2.0      |\n","|      POVRTY_LEV      |  345.26790400000004  |  316.5358743985996   | 0.0  |    132.0425   |   255.815    |     457.4     |   3051.38    |\n","|   APPT_REG_MEDCARE   |        0.6444        |  2.1865956919487846  | -9.0 |      1.0      |     1.0      |      2.0      |     2.0      |\n","|    LOST_ALL_TEETH    |  1.8903333333333334  |  0.675625872982596   | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|    PROB_BILL_PAY     |  1.8361333333333334  |  0.6069367954796526  | -9.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|      ASPRN_REG       |  1.7269333333333334  |  1.069101239695886   | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|        OCCUP         |  2.1241333333333334  |  3.1266450565276758  | -1.0 |      -1.0     |     2.0      |      4.0      |     11.0     |\n","|    DIFF_ERRND_ALN    |  1.9132666666666667  |  0.4179581017524441  | -9.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|      DIAB_KIDNY      | -0.7682666666666667  |  0.8704501753628857  | -9.0 |      -1.0     |     -1.0     |      -1.0     |     2.0      |\n","|      DIAB_INSLN      | -0.7772666666666667  |  0.8067010474730174  | -9.0 |      -1.0     |     -1.0     |      -1.0     |     2.0      |\n","|       DIAB_MED       |        -0.82         |  0.663045480054431   | -9.0 |      -1.0     |     -1.0     |      -1.0     |     2.0      |\n","|     DISPSN_STAT      |  11.547666666666666  |  3.969161729955985   | 11.0 |      11.0     |     11.0     |      11.0     |     44.0     |\n","|    TIME_LAST_PSA     | -0.16813333333333333 |  2.5711291739698567  | -9.0 |      -1.0     |     -1.0     |      -1.0     |     6.0      |\n","| DAYS_CAREOTHR_NOWORK |       -0.5462        |  2.341985885210558   | -9.0 |      -1.0     |     -1.0     |      -1.0     |     15.0     |\n","|  WHEN_ADV_EXERCISE   |       -0.9904        | 0.15929908478466398  | -1.0 |      -1.0     |     -1.0     |      -1.0     |     3.0      |\n","|      UNION_STAT      |  0.7909333333333334  |  1.4293217481028078  | -1.0 |      -1.0     |     2.0      |      2.0      |     2.0      |\n","|         DEAF         | -0.8619333333333333  |  0.6232951376975738  | -1.0 |      -1.0     |     -1.0     |      -1.0     |     2.0      |\n","|        BLIND         |       -0.9016        |  0.5302227667802784  | -1.0 |      -1.0     |     -1.0     |      -1.0     |     2.0      |\n","|     LAST_FLU_VAC     |        2.8696        |  3.0245229413251695  | -8.0 |      1.0      |     2.0      |      6.0      |     6.0      |\n","|     NON_ENG_LANG     | -0.17166666666666666 |  1.1281912115932595  | -1.0 |      -1.0     |     -1.0     |      1.0      |     2.0      |\n","|    UNABL_PRES_MED    |  1.9271333333333334  |  0.5831921836728842  | -9.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|       HEAR_AID       |  1.9487333333333334  |  0.3322334834039048  | -9.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|      PENSN_PLAN      | -1.3829333333333333  |  1.1384119616122648  | -9.0 |      -2.0     |     -2.0     |      -1.0     |     2.0      |\n","|     LAST_REG_CKP     |  1.4356666666666666  |  2.1565183190287724  | -8.0 |      1.0      |     1.0      |      2.0      |     6.0      |\n","|     NO_WORK_WHY      |        0.2598        |  6.234802494398083   | -9.0 |      -1.0     |     -1.0     |      -1.0     |     91.0     |\n","|   DAYS_ILL_NOWORK    |        0.4212        |  8.365296713562888   | -9.0 |      -1.0     |     0.0      |      1.0      |     60.0     |\n","|   DAYS_ILL_NOSCHL    | -1.1029333333333333  |  1.6412548989717506  | -9.0 |      -1.0     |     -1.0     |      -1.0     |     14.0     |\n","|     HIGH_BP_DIAG     |        1.6614        |  0.5484251009384747  | -8.0 |      1.0      |     2.0      |      2.0      |     2.0      |\n","|     COR_HRT_DIAG     |        1.9466        |  0.3120175160606448  | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|     ANGINA_DIAG      |  1.9722666666666666  |  0.282434972202629   | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|     HRT_ATT_DIAG     |  1.9628666666666668  |  0.2292552131411468  | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|     OTH_HRT_DIAG     |        1.8992        |  0.362557751548967   | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|     STROKE_DIAG      |        1.9592        | 0.23651445890811582  | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|     EMPHYM_DIAG      |  1.9792666666666667  | 0.20762065402547042  | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|    HIGHCHOL_DIAG     |  1.6978666666666666  |  0.5474200947531782  | -8.0 |      1.0      |     2.0      |      2.0      |     2.0      |\n","|     CANCER_DIAG      |  1.9093333333333333  | 0.33752108613807097  | -9.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|      DIAB_DIAG       |  1.8898666666666666  |  0.3475802588726059  | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|      ARTHR_DIAG      |  1.7493333333333334  |  0.4905598150593814  | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|      ARTHR_TYPE      | -0.18646666666666667 |  1.4786398955182174  | -7.0 |      -1.0     |     -1.0     |      -1.0     |     3.0      |\n","|      ASTHM_DIAG      |  1.9028666666666667  |  0.3232729743059937  | -8.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|      ADHD_DIAG       |       -0.9224        |  0.4827633416380617  | -9.0 |      -1.0     |     -1.0     |      -1.0     |     2.0      |\n","|   NUM_PRESCR_MEDS    |  12.024333333333333  |  22.53992926156455   | 0.0  |      0.0      |     2.0      |      14.0     |    257.0     |\n","|     DIFFIC_HEAR      |        1.9248        |  0.3848222523161836  | -9.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|      DIFFIC_SEE      |  1.9390666666666667  |  0.3602255493233202  | -9.0 |      2.0      |     2.0      |      2.0      |     2.0      |\n","|         SMOK         |  1.2444666666666666  |  1.7231271940023185  | -9.0 |      1.0      |     2.0      |      2.0      |     2.0      |\n","|     OVR_FEEL_14      | 0.23553333333333334  |  1.807173236640547   | -9.0 |      0.0      |     0.0      |      0.0      |     6.0      |\n","|   MENTAL_HLTH_SCR    |  43.40199466666666   |  21.392242558712336  | -9.0 |    38.8775    |    51.83     |    57.4925    |    75.51     |\n","|     PHY_HLTH_SCR     |      41.278002       |  20.943970562945616  | -9.0 |     33.51     |    51.24     |     56.15     |    72.07     |\n","|     OVR_FEEL_30      |        2.0546        |  4.527845580299677   | -9.0 |      0.0      |     1.0      |      3.0      |     24.0     |\n","|     TOT_MED_EXP      |  4931.666933333333   |   12802.5923404618   | 0.0  |     104.0     |    911.0     |     4015.5    |   236449.0   |\n","+----------------------+----------------------+----------------------+------+---------------+--------------+---------------+--------------+\n"]}],"source":["\n","# Load the training dataset\n","df_train = pd.read_csv('data/train.csv')\n","\n","# Detect categorical and numerical columns\n","categorical_columns = df_train.select_dtypes(include=['object', 'category']).columns.tolist()\n","numerical_columns = df_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n","\n","# Create a PrettyTable to display the information\n","table = PrettyTable()\n","table.field_names = [\"Column Name\", \"Unique Values\"]\n","\n","# Populate the table with categorical columns and their unique values\n","for col in categorical_columns:\n","    unique_vals = df_train[col].unique()\n","    table.add_row([col, unique_vals])\n","\n","# Print the table\n","print(\"Categorical Columns and Unique Values:\")\n","print(table)\n","\n","# Detect numerical columns\n","numerical_columns = df_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n","\n","# Calculate statistics for numerical columns\n","stats = df_train[numerical_columns].describe().transpose()\n","\n","# Create a PrettyTable to display the statistics\n","table_stats = PrettyTable()\n","table_stats.field_names = [\"Column Name\", \"Mean\", \"Standard Deviation\", \"Min\", \"25%\", \"50%\", \"75%\", \"Max\"]\n","\n","# Populate the table with the statistics\n","for col in numerical_columns:\n","    table_stats.add_row([\n","        col,\n","        stats.loc[col, 'mean'],\n","        stats.loc[col, 'std'],\n","        stats.loc[col, 'min'],\n","        stats.loc[col, '25%'],\n","        stats.loc[col, '50%'],\n","        stats.loc[col, '75%'],\n","        stats.loc[col, 'max']\n","    ])\n","\n","# Print the table\n","print(\"Statistics for Numerical Columns:\")\n","print(table_stats)"]},{"cell_type":"code","execution_count":234,"id":"1ef98d09","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['RACE_White', 'UTILIZATION_LOW']\n","Categorical Columns and Unique Values after One-Hot Encoding:\n","+-----------------+---------------+\n","|   Column Name   | Unique Values |\n","+-----------------+---------------+\n","|    RACE_White   | [False  True] |\n","| UTILIZATION_LOW | [ True False] |\n","+-----------------+---------------+\n"]}],"source":["# Encode categorical features using one-hot encoding\n","df_train = pd.get_dummies(df_train, columns=categorical_columns, drop_first=True)\n","new_cols = [] \n","for original_col in categorical_columns:\n","    new_cols.extend([col for col in df_train.columns if col.startswith(original_col)])\n","\n","print(new_cols)\n","\n","table = PrettyTable()\n","table.field_names = [\"Column Name\", \"Unique Values\"]\n","\n","# Populate the table with categorical columns and their unique values\n","for col in new_cols:\n","    unique_vals = df_train[col].unique()\n","    table.add_row([col, unique_vals])\n","\n","# Print the table\n","print(\"Categorical Columns and Unique Values after One-Hot Encoding:\") \n","print(table)"]},{"cell_type":"code","execution_count":235,"id":"4ec5ce23","metadata":{},"outputs":[],"source":["# Normalize numerical features\n","from sklearn.preprocessing import StandardScaler\n","\n","numerical_features = df_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n","scaler = StandardScaler()\n","df_train[numerical_features] = scaler.fit_transform(df_train[numerical_features])"]},{"cell_type":"code","execution_count":236,"id":"08ef4eb8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Statistics for Numerical Columns:\n","+----------------------+-------------------------+--------------------+-----------------------+-----------------------+-----------------------+-----------------------+---------------------+\n","|     Column Name      |           Mean          | Standard Deviation |          Min          |          25%          |          50%          |          75%          |         Max         |\n","+----------------------+-------------------------+--------------------+-----------------------+-----------------------+-----------------------+-----------------------+---------------------+\n","|         SEX          |  1.6247743891047625e-16 | 1.0000333350001158 |  -1.0676142961325987  |  -1.0676142961325987  |   0.9366678618134567  |   0.9366678618134567  |  0.9366678618134567 |\n","|        PANEL         | -3.4489744393795263e-15 | 1.0000333350000403 |  -1.0679002570016158  |  -1.0679002570016158  |   0.9364170421755846  |   0.9364170421755846  |  0.9364170421755846 |\n","|        WEIGHT        |  2.4632148173016805e-17 |  1.0000333350001   |   -1.130414386466274  |  -0.6679078625552956  |   -0.276554281962398  |  0.35932659865181926  |  10.146017085445198 |\n","|     STUDENT_STAT     |  9.473903143468002e-18  | 1.0000333349999742 |   -8.163621233424811  |  -0.3338734932218224  |  -0.3338734932218224  |  -0.3338734932218224  |  3.581000376879672  |\n","|    MIL_ACTIV_DUTY    |  -5.021168666038041e-17 | 1.0000333349999573 |  -13.234431494659649  |  -0.5528405088539422  |  -0.5528405088539422  |  -0.5528405088539422  |  1.7529033067470956 |\n","|    HON_DISCHARGE     |  2.1789977229976406e-17 | 1.000033334999987  |   -14.68481154093387  |  0.14388327515489768  |  0.14388327515489768  |  0.14388327515489768  |  2.8400096053528556 |\n","|     HEALTH_STAT      |  -9.568642174902683e-17 | 1.000033335000052  |   -9.333083059019396  |  -0.34028738818439647 |  -0.34028738818439647 |   0.5589921788991036  |  2.3575513130661037 |\n","|     MENTAL_HLTH      |  1.0421293457814803e-16 | 1.0000333350001545 |   -9.489033916395766  |   -1.035188969068629  |   -0.095872863810058  |   0.8434432414485128  |  2.7220754519656545 |\n","|     CHRON_BRONCH     |  1.3926637620897963e-16 | 1.0000333349999482 |   -21.26657721324465  |  0.08483628295824631  |  0.08483628295824631  |  0.08483628295824631  | 0.08483628295824631 |\n","|       JNT_PAIN       |  -6.821210263296961e-17 | 1.000033335000084  |  -13.059273964524323  |  -0.8627884217309394  |   0.4923766385794365  |   0.4923766385794365  |  0.4923766385794365 |\n","|        PREGNT        |  -3.600083194517841e-17 | 1.0000333350001256 |  -6.7838406026535765  |   -0.582842177022446  |   -0.582842177022446  |   0.9674074293853365  |  1.7425322325892276 |\n","|       WALK_LIM       |  2.2358411418584484e-16 | 1.0000333350001516 |  -18.026568901509993  |   0.2791004385379309  |   0.2791004385379309  |   0.2791004385379309  |  0.2791004385379309 |\n","|      ACTIV_LIM       |  1.4779288903810083e-16 | 1.0000333350002255 |  -15.782187744470697  |   0.2214909126140531  |   0.2214909126140531  |   0.2214909126140531  |  0.2214909126140531 |\n","|      SOCIAL_LIM      |  2.813749233609997e-16  | 1.000033335000265  |  -29.113596183257794  |  0.19204966579747584  |  0.19204966579747584  |  0.19204966579747584  | 0.19204966579747584 |\n","|      COGNTV_LIM      |  1.3073986337985843e-16 | 1.0000333350001718 |  -17.562355599540492  |   0.1524655607865482  |   0.1524655607865482  |   0.1524655607865482  |  0.1524655607865482 |\n","|       EMPLYMT        |  1.0421293457814803e-16 | 1.000033335000213  |   -7.533715975291917  |  -0.7407911006613759  |  -0.7407911006613759  |   1.2970863617277866  |  1.2970863617277866 |\n","|        REGION        | -1.6058265828178263e-16 | 1.0000333350000756 |  -1.7532300783220587  |  -0.7708815976963489  |  0.21146688292936097  |   1.1938153635550708  |  1.1938153635550708 |\n","|     MARITAL_STAT     |  3.979039320256561e-17  | 1.0000333350001467 |  -0.9349208372448713  |  -0.9349208372448713  |  -0.4043789933878339  |   1.1872465381832784  |  3.8399557574684655 |\n","|         AGE          |  1.4163485199484664e-16 | 1.0000333350001032 |   -1.563563823100609  |  -0.8349814983739962  |  -0.05035437943764376 |   0.7342727394987085  |  2.1914373889519343 |\n","|      POVRTY_CAT      | -1.1368683772161604e-17 | 1.0000333350000936 |   -1.752969949561311  |  -0.35268508198118187 |  0.34745735180888265  |   1.0475997855989472  |  1.0475997855989472 |\n","|      INSUR_COV       |  1.5158245029548803e-16 | 1.000033335000098  |  -0.7550628807394433  |  -0.7550628807394433  |  -0.7550628807394433  |   0.6199454003206091  |  1.9949536813806614 |\n","|      TOT_INCOME      |  4.6658972981579913e-17 | 1.000033335000079  |  -0.8919897570782596  |  -0.6412190255516333  |  -0.2858211721491758  |   0.3022361932807628  |  10.50743470300066  |\n","|        BM_IDX        |  4.926429634603361e-17  | 1.000033335000101  |   -2.660705686462603  |  -0.6799590465388712  |  -0.14381709889034194 |  0.49657467191206783  |  20.021077265445996 |\n","|     MULT_HIGHBP      | -2.2737367544323207e-17 | 1.0000333350001562 |   -7.36926877399287   |  -0.5780462258863346  |  -0.5780462258863346  |   1.119759411140299   |  1.968662229653616  |\n","|     HOUSEWRK_LIM     | -1.8947806286936006e-18 | 1.0000333349998802 |   -8.443639632899151  |  -0.27207421616110666 |  -0.27207421616110666 |  -0.27207421616110666 |  3.230025248155198  |\n","|      SCHOOL_LIM      |  1.1416053287878943e-16 | 1.0000333350001642 |   -8.00359762089238   |  -0.27854338419188635 |  -0.27854338419188635 |  -0.27854338419188635 |  3.032194145822612  |\n","|   ADV_NO_FAT_FOOD    |  4.121147867408581e-17  | 1.0000333349999875 |   -5.460115454216173  |  -0.2062998269634566  |  0.37745746495351185  |  0.37745746495351185  | 0.37745746495351185 |\n","|  ADV_EXERCISE_MORE   |  3.789561257387201e-17  | 1.0000333349999884 |   -5.677198366479095  |  -0.18612698261168345 |   0.4239920600402511  |   0.4239920600402511  |  0.4239920600402511 |\n","|     ADV_DNTL_CKP     |  1.1581846592889632e-16 | 1.0000333350002302 |  -29.097659046221462  |   -0.070391124709666  |   -0.070391124709666  |   -0.070391124709666  |  10.814834345857257 |\n","|    FREQ_DNTL_CKP     | -4.7369515717340015e-17 | 1.0000333350001254 |   -6.262787418047601  |  -0.6885614268794128  |  -0.0692029834162807  |   0.5501554600468513  |  1.1695139035099835 |\n","|   RSN_NO_DNTL_CKP    | -1.2197650297215053e-17 | 1.0000333350001849 |  -1.3543340936281538  |  -0.08099640408082487 |  -0.08099640408082487 |  -0.08099640408082487 |  16.654298944255498 |\n","|    RSN_NO_MED_CKP    |  -7.342274936187702e-18 | 1.000033335000199  |  -0.07377124620331756 |  -0.07377124620331756 |  -0.07377124620331756 |  -0.07377124620331756 |  16.103619467379747 |\n","|      EMPLYR_INS      |  -3.552713678800501e-17 | 1.0000333350000126 |  -2.7215676160335156  |   -0.066703461873276  |   -0.066703461873276  |   0.5970125766667838  |  0.9288705959368136 |\n","|      DOC_CK_BP       |  2.842170943040401e-18  | 1.000033335000151  |   -5.701709087864016  |  0.22514128967477348  |  0.22514128967477348  |  0.22514128967477348  |  0.8178263274286524 |\n","|      TAKE_RISK       |  5.826450433232822e-17  | 1.0000333350000747 |   -4.480950604222252  |  -0.20120510188329546 |  -0.20120510188329546 |   0.6547439985844958  |  1.5106930990522873 |\n","| NUM_DEP_OUT_REP_UNT  |  1.0231815394945442e-16 | 1.0000333350001096 |  -15.642700086166958  |  -0.14611069992740142 |  -0.14611069992740142 |  -0.14611069992740142 |  17.564277170060663 |\n","|    ADV_BOOST_SEAT    |  9.019155792581539e-16  | 1.0000333350000647 | -0.008165237988412368 | -0.008165237988412368 | -0.008165237988412368 | -0.008165237988412368 |  122.47040458821061 |\n","| WHEN_ADV_BOOST_SEAT  |  9.019155792581539e-16  | 1.0000333350000647 | -0.008165237988412368 | -0.008165237988412368 | -0.008165237988412368 | -0.008165237988412368 |  122.47040458821061 |\n","|      FEEL_DEPRS      |  -3.221127068779121e-17 | 1.0000333350000896 |   -5.26389860805964   |  -0.15758646637261894 |   0.2679395454346329  |   0.6934655572418846  |  0.6934655572418846 |\n","|     ADV_NO_SMKG      |  -2.842170943040401e-18 | 1.0000333350001644 |   -5.778586243250615  |  -0.14391879767247504 |  -0.14391879767247504 |  -0.14391879767247504 |  2.673414925116595  |\n","|    AGE_DIAG_ADHD     |  -5.684341886080802e-17 | 1.0000333350000614 |  -12.085495536439884  |  -0.04792101096806882 |  -0.04792101096806882 |  -0.04792101096806882 |  30.905842054530886 |\n","|      CHILD_SUPP      |  5.210646728907401e-17  | 1.0000333350000983 |  -0.11284062032251374 |  -0.11284062032251374 |  -0.11284062032251374 |  -0.11284062032251374 |  29.521447804384692 |\n","|      PROB_WKIDS      |  3.221127068779121e-17  | 1.0000333350002708 |   -9.631212438467879  | -0.022100956408735994 | -0.022100956408735994 | -0.022100956408735994 |  120.09179256933055 |\n","|      PROB_WBHV       |  5.589602854646121e-17  | 1.0000333350002686 |   -9.59886907509476   | -0.023459752839525262 | -0.023459752839525262 | -0.023459752839525262 |  119.6691567753509  |\n","|     WEAR_SEATBLT     | -1.5785891112803559e-16 | 1.000033335000152  |   -11.96484555536051  |  -0.20676797172991884 |  -0.20676797172991884 |  -0.20676797172991884 |  6.325497352509299  |\n","|       PUB_ASST       |  -8.526512829121201e-18 | 1.0000333350000243 |  -0.08599627397928225 |  -0.08599627397928225 |  -0.08599627397928225 |  -0.08599627397928225 |  24.01317416324566  |\n","|       EDU_DEG        |  8.526512829121201e-18  | 1.0000333350000195 |   -4.025970191402422  |  -0.8727157272071198  |  -0.08440211115829423 |   0.7039115048905312  |  2.2805387369881824 |\n","|     SPOUSE_PRSNT     | -4.6422125402993215e-17 | 1.0000333350002133 |  -1.0839089602862308  |  -1.0839089602862308  |   0.9225867085146408  |   0.9225867085146408  |  0.9225867085146408 |\n","|     TAX_FORM_TYP     |  3.0790185216271007e-18 | 1.0000333350001376 |   -1.074298619667509  |  -0.0593012229058027  |  -0.0593012229058027  |  0.19444812628462388  |  11.61316883985382  |\n","|   FOOD_STMP_MNTHS    |  3.789561257387201e-17  | 1.0000333350000061 |  -2.2275016818870084  |  -0.4182897895161439  |  -0.4182897895161439  |  -0.4182897895161439  |  2.521679535586511  |\n","|    FOOD_STMP_VAL     | -5.3053857603420813e-17 |  1.00003333499996  |  -0.37352433768604987 |  -0.3221725173870062  |  -0.3221725173870062  |  -0.3221725173870062  |   32.6970479348981  |\n","|   WHEN_ADV_LAP_BLT   |  2.7047993474601146e-16 | 1.0000333349999762 |  -0.05763680067555473 |  -0.05763680067555473 |  -0.05763680067555473 |  -0.05763680067555473 |  24.29594094955895  |\n","|       EDU_YRS        |  3.600083194517841e-17  | 1.000033335000012  |   -2.104614951928922  |   -1.007794860590997  |   0.226127742164169   |   0.9116402992503723  |  1.4600503449193352 |\n","|   WHEN_LST_ASTHMA    |  1.1321314256444263e-16 | 1.0000333350000195 |  -16.249321868023898  |  -0.10266582136334988 |  -0.10266582136334988 |  -0.10266582136334988 |  12.00732621363206  |\n","|      FAM_INCOME      |  1.7053025658242403e-17 | 1.0000333350000894 |  -1.0748437781687215  |  -0.6918140539522587  |  -0.27506011876424047 |   0.373310331079337   |  7.6175549375901666 |\n","|   DELAY_PRESCR_MED   |  6.063298011819522e-17  | 1.0000333350001456 |  -18.350500885702537  |  0.13816072586095637  |  0.13816072586095637  |  0.13816072586095637  | 0.13816072586095637 |\n","|     ADV_LAP_BLT      | -1.7053025658242403e-17 | 1.0000333350001078 |   -28.33184186445593  |  -0.07464609216513486 |  -0.07464609216513486 |  -0.07464609216513486 |  10.521802322443914 |\n","|    ADV_EAT_HLTHY     |  -2.913225216616411e-17 | 1.000033335000015  |   -30.57766083463259  |  -0.07676059892652692 |  -0.07676059892652692 |  -0.07676059892652692 |  11.361076989463244 |\n","|     DOC_TIM_ALN      |  1.8947806286936006e-16 | 1.0000333349999773 |   -27.9452710155696   |  -0.07548068215300309 |  -0.07548068215300309 |  -0.07548068215300309 |  10.375690692878221 |\n","|      POVRTY_LEV      | -1.3831898589463284e-16 | 1.0000333350000974 |  -1.0908065765424666  |  -0.6736440609583114  |  -0.2826089967923052  |  0.35425947891840864  |  8.549433170532753  |\n","|   APPT_REG_MEDCARE   | -1.7053025658242403e-17 | 1.000033335000019  |  -4.4108389729242115  |   0.1626326509447814  |   0.1626326509447814  |   0.6199798133316806  |  0.6199798133316806 |\n","|    LOST_ALL_TEETH    | -1.6153004859612945e-16 | 1.0000333350000032 |  -14.639260311231252  |   0.1623240417375578  |   0.1623240417375578  |   0.1623240417375578  |  0.1623240417375578 |\n","|    PROB_BILL_PAY     |  -5.589602854646121e-17 | 1.000033335000272  |  -17.854403681811224  |  0.26999867265009647  |  0.26999867265009647  |  0.26999867265009647  | 0.26999867265009647 |\n","|      ASPRN_REG       |  -7.910709124795782e-17 | 1.000033335000212  |   -9.098537369035807  |  0.25542554737067286  |  0.25542554737067286  |  0.25542554737067286  | 0.25542554737067286 |\n","|        OCCUP         |  2.936909974475081e-17  | 1.000033335000079  |  -0.9992299796855894  |  -0.9992299796855894  |  -0.03970309039679418 |   0.5999815024624027  |  2.838877577469592  |\n","|    DIFF_ERRND_ALN    |  -3.979039320256561e-17 | 1.0000333350000865 |   -26.11178109636208  |  0.20752373078862463  |  0.20752373078862463  |  0.20752373078862463  | 0.20752373078862463 |\n","|      DIAB_KIDNY      |  2.4158453015843405e-17 | 1.0000333350002257 |   -9.457184306651648  |  -0.2662312728783013  |  -0.2662312728783013  |  -0.2662312728783013  |  3.1803761147867036 |\n","|      DIAB_INSLN      |  2.7000623958883807e-17 | 1.0000333350001154 |  -10.193376423530434  |  -0.2761131386239383  |  -0.2761131386239383  |  -0.2761131386239383  |  3.4428605932159972 |\n","|       DIAB_MED       | -1.0089706847793423e-16 | 1.0000333350002057 |  -12.337423187968277  |  -0.27148363983304286 |  -0.27148363983304286 |  -0.27148363983304286 |   4.25324369071767  |\n","|     DISPSN_STAT      |  5.3053857603420813e-17 | 1.0000333349999224 |  -0.1379850357322591  |  -0.1379850357322591  |  -0.1379850357322591  |  -0.1379850357322591  |  8.176390215329008  |\n","|    TIME_LAST_PSA     |  1.2316074086508403e-17 | 1.0000333350001647 |   -3.435129267856578  |  -0.32355215963642553 |  -0.32355215963642553 |  -0.32355215963642553 |  2.399077810056208  |\n","| DAYS_CAREOTHR_NOWORK | -1.4210854715202004e-17 | 1.0000333350001613 |  -3.6097919551139785  |   -0.193773638982555  |   -0.193773638982555  |   -0.193773638982555  |  6.638262993280293  |\n","|  WHEN_ADV_EXERCISE   | -3.4579746473658207e-16 | 1.0000333350001285 |  -0.06026600861504725 |  -0.06026600861504725 |  -0.06026600861504725 |  -0.06026600861504725 |  25.05057091432117  |\n","|      UNION_STAT      |  2.936909974475081e-17  | 1.0000333350001298 |  -1.2530369991735437  |  -1.2530369991735437  |   0.8459305768690959  |   0.8459305768690959  |  0.8459305768690959 |\n","|         DEAF         |  -3.979039320256561e-17 | 1.000033335000186  |  -0.2215182836641996  |  -0.2215182836641996  |  -0.2215182836641996  |  -0.2215182836641996  |  4.5917713179239135 |\n","|        BLIND         |  -6.679101716144942e-17 | 1.0000333350002342 |  -0.18558856075069702 |  -0.18558856075069702 |  -0.18558856075069702 |  -0.18558856075069702 |  5.472599267014454  |\n","|     LAST_FLU_VAC     | -4.6422125402993215e-17 | 1.0000333350001511 |  -3.5939427635337653  |   -0.618167677808082  |  -0.2875260016163394  |   1.035040703150631   |  1.035040703150631  |\n","|     NON_ENG_LANG     |           0.0           | 1.0000333350001445 |  -0.7342380771210415  |  -0.7342380771210415  |  -0.7342380771210415  |   1.038570157376443   |  1.9249742746251854 |\n","|    UNABL_PRES_MED    |  -6.252776074688882e-17 | 1.0000333349999944 |   -18.73738691164307  |  0.12494868367077591  |  0.12494868367077591  |  0.12494868367077591  | 0.12494868367077591 |\n","|       HEAR_AID       | -2.5484799455928925e-16 | 1.0000333350001924 |   -32.95603500640381  |  0.15431429462114024  |  0.15431429462114024  |  0.15431429462114024  | 0.15431429462114024 |\n","|      PENSN_PLAN      |  5.2106467289074014e-18 | 1.0000333349999737 |   -6.69118108245882   |  -0.5420596913881007  |  -0.5420596913881007  |   0.336386221622002   |   2.97172396065231  |\n","|     LAST_REG_CKP     |  3.836930773104541e-17  | 1.0000333350001358 |   -4.375562739882491  |  -0.2020299043002231  |  -0.2020299043002231  |   0.2616959663200289  |  2.116599448801037  |\n","|     NO_WORK_WHY      |  2.7000623958883807e-17 | 1.0000333350000845 |  -1.4852288719257956  |  -0.2020660632899325  |  -0.2020660632899325  |  -0.2020660632899325  |  14.554306236022493 |\n","|   DAYS_ILL_NOWORK    | -1.8947806286936004e-17 | 1.0000333350000346 |  -1.1262617906221895  |  -0.16989802327009887 | -0.050352552351087564 |  0.06919291856792374  |  7.122375702789591  |\n","|   DAYS_ILL_NOSCHL    |  -3.031649005909761e-17 | 1.0000333350002715 |   -4.811763194329471  |  0.06271832893263914  |  0.06271832893263914  |  0.06271832893263914  |  9.202371185049095  |\n","|     HIGH_BP_DIAG     |  1.8947806286936004e-17 | 1.0000333350002009 |  -17.617213446714675  |   -1.206038977131377  |   0.6174248528223228  |   0.6174248528223228  |  0.6174248528223228 |\n","|     COR_HRT_DIAG     | -3.4579746473658207e-16 | 1.000033334999916  |  -31.879401180723686  |   0.1711499430006878  |   0.1711499430006878  |   0.1711499430006878  |  0.1711499430006878 |\n","|     ANGINA_DIAG      |  1.8924121529077334e-16 | 1.000033335000104  |   -35.30936347719971  |  0.09819696763367144  |  0.09819696763367144  |  0.09819696763367144  | 0.09819696763367144 |\n","|     HRT_ATT_DIAG     |  -4.339047639708345e-16 | 1.0000333350000048 |   -43.45898460635041  |  0.16197917885573176  |  0.16197917885573176  |  0.16197917885573176  | 0.16197917885573176 |\n","|     OTH_HRT_DIAG     |  2.6290081223123708e-17 | 1.0000333350001884 |   -27.30469821025731  |   0.2780339400753532  |   0.2780339400753532  |   0.2780339400753532  |  0.2780339400753532 |\n","|     STROKE_DIAG      | -1.9042545318370686e-16 | 1.0000333350002555 |   -42.10961154726022  |  0.17251106023859497  |  0.17251106023859497  |  0.17251106023859497  | 0.17251106023859497 |\n","|     EMPHYM_DIAG      | -3.1311249889161746e-16 | 1.0000333349999848 |   -48.06650558137057  |  0.09986494155085678  |  0.09986494155085678  |  0.09986494155085678  | 0.09986494155085678 |\n","|    HIGHCHOL_DIAG     |  8.337034766251842e-17  | 1.0000333350001094 |   -17.7161745394565   |  -1.2748708656132663  |   0.5519406537026484  |   0.5519406537026484  |  0.5519406537026484 |\n","|     CANCER_DIAG      |  4.0264088359739013e-17 | 1.0000333349999528 |   -32.32300867715121  |  0.26863414691350307  |  0.26863414691350307  |  0.26863414691350307  | 0.26863414691350307 |\n","|      DIAB_DIAG       |  2.4584778657299466e-16 | 1.0000333350001778 |  -28.454424821049876  |  0.31686783646813194  |  0.31686783646813194  |  0.31686783646813194  | 0.31686783646813194 |\n","|      ARTHR_DIAG      | -1.4116115683767325e-16 | 1.0000333349999702 |  -19.874555615979233  |   0.5109978741526388  |   0.5109978741526388  |   0.5109978741526388  |  0.5109978741526388 |\n","|      ARTHR_TYPE      | -1.2079226507921702e-17 | 1.000033335000221  |  -4.6081270247881445  |  -0.5502086443987919  |  -0.5502086443987919  |  -0.5502086443987919  |  2.1550702758607763 |\n","|      ASTHM_DIAG      | -1.3547681495159243e-16 | 1.0000333350002986 |  -30.634162351460088  |   0.3004784779227384  |   0.3004784779227384  |   0.3004784779227384  |  0.3004784779227384 |\n","|      ADHD_DIAG       | -2.3684757858670008e-17 | 1.0000333349999226 |   -16.73256556594964  |  -0.16074664354730264 |  -0.16074664354730264 |  -0.16074664354730264 |  6.053685452353573  |\n","|   NUM_PRESCR_MEDS    |  5.684341886080802e-18  | 1.0000333350000519 |  -0.5334858874198565  |  -0.5334858874198565  |  -0.44475150645572425 |  0.08765477932906855  |  10.868882066471123 |\n","|     DIFFIC_HEAR      | -1.7810937909719845e-16 | 1.000033335000036  |  -28.390157046405925  |  0.19542140907748645  |  0.19542140907748645  |  0.19542140907748645  | 0.19542140907748645 |\n","|      DIFFIC_SEE      | -1.6745123806079694e-16 | 1.0000333350001043 |   -30.36828270788535  |  0.16915891907296896  |  0.16915891907296896  |  0.16915891907296896  | 0.16915891907296896 |\n","|         SMOK         | -2.9842794901924206e-17 | 1.0000333350000323 |  -5.9454741365712165  |  -0.14187856637278431 |   0.4384809906470589  |   0.4384809906470589  |  0.4384809906470589 |\n","|     OVR_FEEL_14      |  5.2106467289074014e-18 | 1.000033334999955  |   -5.110656251753468  |  -0.1303368044974483  |  -0.1303368044974483  |  -0.1303368044974483  |  3.1898761603398986 |\n","|   MENTAL_HLTH_SCR    |  3.320603051785535e-16  | 1.0000333350000934 |  -2.4496609620679206  |  -0.21150870360032525 |   0.3939879728719534  |   0.6586955529162909  |  1.500968192818957  |\n","|     PHY_HLTH_SCR     | -1.1368683772161604e-17 | 1.000033335000097  |  -2.4006755484156996  |  -0.37090679262561504 |  0.47566577947878885  |   0.7101086068353946  |  1.470257244618931  |\n","|     OVR_FEEL_30      |  -6.039613253960852e-17 | 1.0000333350001724 |  -2.4415515743715317  |  -0.45378501842705743 |  -0.2329220677665603  |  0.20880383355443394  |  4.846925797424873  |\n","|     TOT_MED_EXP      |  2.7948014273230605e-17 | 1.0000333350001167 |  -0.3852213051308677  |  -0.37709767953425194 |  -0.3140614693758969  |  -0.07156343413845802 |  18.08423204769799  |\n","+----------------------+-------------------------+--------------------+-----------------------+-----------------------+-----------------------+-----------------------+---------------------+\n"]}],"source":["# Calculate statistics for numerical columns\n","stats = df_train[numerical_columns].describe().transpose()\n","\n","# Create a PrettyTable to display the statistics\n","table_stats = PrettyTable()\n","table_stats.field_names = [\"Column Name\", \"Mean\", \"Standard Deviation\", \"Min\", \"25%\", \"50%\", \"75%\", \"Max\"]\n","\n","# Populate the table with the statistics\n","for col in numerical_columns:\n","    table_stats.add_row([\n","        col,\n","        stats.loc[col, 'mean'],\n","        stats.loc[col, 'std'],\n","        stats.loc[col, 'min'],\n","        stats.loc[col, '25%'],\n","        stats.loc[col, '50%'],\n","        stats.loc[col, '75%'],\n","        stats.loc[col, 'max']\n","    ])\n","\n","# Print the table\n","print(\"Statistics for Numerical Columns:\")\n","print(table_stats)"]},{"cell_type":"markdown","id":"9c2323d4","metadata":{"id":"9c2323d4"},"source":["# Linear regression"]},{"cell_type":"markdown","id":"GjxnefI-aSOZ","metadata":{"id":"GjxnefI-aSOZ"},"source":["In this part, we will solve an linear regression task to predict our target `TOT_MED_EXP`, i.e. total medical expences, using the other features.\n"]},{"cell_type":"markdown","id":"2_CBqwiigmaF","metadata":{"id":"2_CBqwiigmaF"},"source":["In its simplest form, predictions of a linear regression model can be summarized as\n","\n","$$\n","\\hat{y} = \\mathbf{w}^T \\mathbf{x} = f(\\mathbf{x},\\mathbf{w})\n","$$\n","\n","which can be optimized using the cost function\n","\n","$$\n","\\mathbf{w}^{*}=\\underset{\\mathbf{w}}{\\arg \\min } \\frac{1}{n} \\sum_{i=1}^{n}\\left(y_{i}-f\\left(\\mathbf{x}_{i}, \\mathbf{w}\\right)\\right)^{2}\n","$$"]},{"cell_type":"markdown","id":"f878db27","metadata":{"id":"f878db27"},"source":["### Process the data"]},{"cell_type":"code","execution_count":237,"id":"JzZwQFApeUBd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1716808586474,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"JzZwQFApeUBd","outputId":"63b1cb7d-ff8e-4842-fe8e-11de1153838b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Labels have shape (15000,) features have shape (15000, 108)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","from sklearn.preprocessing import LabelEncoder\n","# df_train['RACE'] = LabelEncoder().fit_transform(df_train['RACE'])\n","\n","y = df_train['TOT_MED_EXP']\n","X = df_train.drop(columns=['TOT_MED_EXP', 'UTILIZATION_LOW'])\n","\n","print(\"Labels have shape {}\".format(y.shape), \"features have shape {}\".format(X.shape))\n","\n","# Split X and y for training and validation purposes\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","id":"464b2bd9","metadata":{"id":"464b2bd9"},"source":["### Train a linear regression model"]},{"cell_type":"code","execution_count":238,"id":"e8be7dc9","metadata":{"executionInfo":{"elapsed":405,"status":"ok","timestamp":1716808586873,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"e8be7dc9"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","\n","reg = LinearRegression().fit(X_train, y_train)"]},{"cell_type":"markdown","id":"TarmeeGneDFb","metadata":{"id":"TarmeeGneDFb"},"source":["### Evaluate the linear regression model"]},{"cell_type":"code","execution_count":239,"id":"dba9ff00","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1716808828969,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"dba9ff00","outputId":"a508ea65-c71f-4a67-b665-647c5a88e169"},"outputs":[{"name":"stdout","output_type":"stream","text":["Split: training data\n","\n","\tRMSE: 0.83\n","\tMAE: 0.35\n","\tsqrt(median((y-pred)**2)): 0.15923760550630786\n","\tmedian(abs(y-pred)): 0.1592376004356687\n","\n","\n","\n","Split: validation data\n","\n","\tRMSE: 0.87\n","\tMAE: 0.38\n","\tsqrt(median((y-pred)**2)): 0.16058296358080704\n","\tmedian(abs(y-pred)): 0.16058295911875692\n","\n","\n","\n"]}],"source":["import sklearn.metrics as skm\n","import numpy as np\n","\n","datasets = {\n","    \"training data\": [X_train, y_train],\n","    \"validation data\": [X_val, y_val]\n","}\n","\n","for split_name, dataset in datasets.items():\n","    print(f'Split: {split_name}\\n')\n","\n","    X_i, y_i = dataset\n","    y_pred = reg.predict(X_i)\n","\n","    rmse = np.sqrt(skm.mean_squared_error(y_i, y_pred))\n","    print(f\"\\tRMSE: {rmse:.2f}\")\n","\n","    mae = skm.mean_absolute_error(y_i, y_pred)\n","    print(f\"\\tMAE: {mae:.2f}\")\n","\n","    # These might also be helpful to look at. Think about why!\n","    print(\"\\tsqrt(median((y-pred)**2)):\",np.sqrt(np.median((y_i-y_pred)**2)))\n","    print(\"\\tmedian(abs(y-pred)):\",np.median(abs(y_i-y_pred)))\n","\n","    print('\\n\\n')"]},{"cell_type":"markdown","id":"5818dbc4","metadata":{"id":"5818dbc4"},"source":["### Export test set predictions for regression task"]},{"cell_type":"markdown","id":"qBItenN5erIi","metadata":{"id":"qBItenN5erIi"},"source":["At this point, we can use our model to predict the medical expenses from the test sets. The following cell shows an example on how to do this.\n","\n","You must save your predictions (`y_hat`) to a file and name the file in the following format:\n","\n","`<TEAM_ID>__<SPLIT>__reg_pred.npy`\n","\n","Make sure that:\n","\n","`<TEAM_ID>` is your team id as given in CMS.\n","\n","`<SPLIT>` is \"test_public\" during the semester and \"test_private\" for the final submission. We will write an announcement to CMS once the test_private dataset is available to download."]},{"cell_type":"code","execution_count":240,"id":"91ee5e03","metadata":{"executionInfo":{"elapsed":384,"status":"ok","timestamp":1716808940546,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"91ee5e03"},"outputs":[{"ename":"ValueError","evalue":"The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- RACE\nFeature names seen at fit time, yet now missing:\n- RACE_White\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[240], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Process data\u001b[39;00m\n\u001b[1;32m      7\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRACE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m LabelEncoder()\u001b[38;5;241m.\u001b[39mfit_transform(df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRACE\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m reg\u001b[38;5;241m.\u001b[39mpredict(df_test)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Save the results with the format <TEAM_ID>__<SPLIT>__reg_pred.npy\u001b[39;00m\n\u001b[1;32m     13\u001b[0m folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m\n","File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.12/site-packages/sklearn/linear_model/_base.py:286\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decision_function(X)\n","File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.12/site-packages/sklearn/linear_model/_base.py:269\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    267\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 269\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m], reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n","File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.12/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n","File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.12/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n","\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- RACE\nFeature names seen at fit time, yet now missing:\n- RACE_White\n"]}],"source":["# Run this to save a file with your predictions on the test set to be submitted\n","split = 'test_public' # replace by 'test_private' for FINAL submission\n","\n","df_test =  pd.read_csv(f'data/{split}.csv')\n","\n","# Process data\n","df_test['RACE'] = LabelEncoder().fit_transform(df_test['RACE'])\n","\n","y_hat = reg.predict(df_test)\n","\n","# Save the results with the format <TEAM_ID>__<SPLIT>__reg_pred.npy\n","\n","folder = './'\n","np.save(os.path.join(folder, f'{team_id}__{split}__reg_pred.npy'), y_hat) # Note the double underscores '__' in the filename"]},{"cell_type":"markdown","id":"34410538","metadata":{"id":"34410538"},"source":["# Linear classification"]},{"cell_type":"markdown","id":"WeqFeth6hb6w","metadata":{"id":"WeqFeth6hb6w"},"source":["In this part, we will train a simple linear classification model to predict our target `UTILIZATION`.\n"]},{"cell_type":"code","execution_count":null,"id":"7ad5ec07","metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1716808587990,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"7ad5ec07"},"outputs":[],"source":["from sklearn import linear_model\n","from sklearn import preprocessing\n","import numpy as np"]},{"cell_type":"markdown","id":"_QIyfxXthmTT","metadata":{"id":"_QIyfxXthmTT"},"source":["We will first change our targets (classes: LOW, HIGH) to numeric targets. Then, we solve a logistic regression problem by minimizing the binary cross-entropy function\n","\n","$$\n","J(\\theta) = -\\frac{1}{n} \\sum_{i=1}^{n} \\left( y_i \\log(p_{\\theta}(\\hat{y}=1 | \\mathbf{x}_i)) + (1 - y_i) \\log(p_{\\theta}(\\hat{y}=0 | \\mathbf{x}_i)) \\right)\n","$$\n","\n","where $y_i \\in \\{0, 1\\}$ and $p_{\\theta}(\\hat{y}=k | \\mathbf{x}_i)$ is the probability assigned by our model to class $k$ having observed features $\\mathbf{x}_i$.\n","\n","0 refers to HIGH, and 1 refers to LOW"]},{"cell_type":"markdown","id":"f6d08d2d","metadata":{"id":"f6d08d2d"},"source":["### Process the data"]},{"cell_type":"code","execution_count":null,"id":"5f516bc9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":744,"status":"ok","timestamp":1716809033654,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"5f516bc9","outputId":"277dbcdf-5798-4312-a723-3d1ae52645c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original classes ['HIGH' 'LOW']\n","Corresponding numeric classes [0 1]\n","Shape of X: (15000, 108)\n","Shape of y: (15000,) , unique entries in y: [0 1]\n"]}],"source":["df_train =  pd.read_csv(f'data/train.csv')\n","\n","y = df_train['UTILIZATION']\n","\n","df_train.drop(columns=['UTILIZATION','TOT_MED_EXP'])\n","\n","le = preprocessing.LabelEncoder()\n","df_test['RACE'] = le.fit_transform(df_test['RACE'])\n","\n","y = le.fit_transform(y) # maps HIGH to 0 and LOW to 1\n","\n","print(f'Original classes {le.classes_}')\n","print(f'Corresponding numeric classes {le.transform(le.classes_)}')\n","\n","\n","print(f\"Shape of X: {X.shape}\")\n","print(f\"Shape of y: {y.shape}\", f\", unique entries in y: {np.unique(y)}\")\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# These hyperparameters are just placeholders, choosen without much care. For a good LogisticRegression baseline, play with them a bit.\n","clf = linear_model.LogisticRegression(penalty=None,\n","                                      dual=False,\n","                                      tol=0.0001,\n","                                      C=1.0,\n","                                      fit_intercept=True,\n","                                      intercept_scaling=1,\n","                                      class_weight=None, # None, balanced\n","                                      random_state=None,\n","                                      solver='lbfgs',\n","                                      max_iter=1500,\n","                                      multi_class='auto',\n","                                      verbose=0,\n","                                      warm_start=False,\n","                                      n_jobs=None,\n","                                      l1_ratio=None\n","                                     )"]},{"cell_type":"markdown","id":"0S5pf_bA2XAV","metadata":{"id":"0S5pf_bA2XAV"},"source":["### Fit the model by using training data"]},{"cell_type":"code","execution_count":null,"id":"c167c0b4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4083,"status":"ok","timestamp":1716809070913,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"c167c0b4","outputId":"b6c6a051-fc21-42d1-ab55-cd4dd453eddc"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/camilo/miniconda3/envs/torch/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"source":["clf = clf.fit(X_train, y_train)\n"]},{"cell_type":"markdown","id":"URLzKp2J2x6i","metadata":{"id":"URLzKp2J2x6i"},"source":["Now evaluate your model. Check the appendix for details on micro, macro and weighted averaging"]},{"cell_type":"code","execution_count":null,"id":"ff8e0e50","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":396,"status":"ok","timestamp":1716809077809,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"ff8e0e50","outputId":"faa68cba-35cf-4203-c592-4879fdb63226"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Split: training data\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.46      0.57      2565\n","           1       0.87      0.95      0.91      9435\n","\n","    accuracy                           0.85     12000\n","   macro avg       0.80      0.71      0.74     12000\n","weighted avg       0.84      0.85      0.84     12000\n","\n","\n","Split: validation data\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.47      0.58       647\n","           1       0.87      0.96      0.91      2353\n","\n","    accuracy                           0.85      3000\n","   macro avg       0.82      0.71      0.75      3000\n","weighted avg       0.85      0.85      0.84      3000\n","\n"]}],"source":["datasets = {\n","    \"training data\": [X_train, y_train],\n","    \"validation data\": [X_val, y_val]\n","}\n","\n","for split_name, dataset in datasets.items():\n","    X_i, y_i = dataset\n","    y_pred = clf.predict(X_i)\n","    print(f'\\nSplit: {split_name}')\n","\n","    print(skm.classification_report(y_i, y_pred))"]},{"cell_type":"markdown","id":"sGxdMSXO2-xH","metadata":{"id":"sGxdMSXO2-xH"},"source":["At this point, we can use our model to predict healthcare utilization on the test set.\n","\n","We again need to follow a specific namim format when saving the predictions. Similarly to before, the name of the file should be `<TEAM_ID>__<SPLIT>__clf_pred.npy`.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"d0cea870","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716808592027,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"d0cea870"},"outputs":[],"source":["# Run this to save a file with your predictions on the test set to be submitted\n","\n","split = 'test_public' # replace by 'test_private' for FINAL submission\n","\n","df_test =  pd.read_csv(f'data/{split}.csv')\n","\n","# Process data\n","df_test['RACE'] = LabelEncoder().fit_transform(df_test['RACE'])\n","\n","y_hat = clf.predict(df_test)\n","\n","# Save the results with the format <TEAM_ID>__<SPLIT>__clf_pred.npy\n","\n","folder = './'\n","np.save(os.path.join(folder, f'{team_id}__{split}__clf_pred.npy'), y_hat)"]},{"cell_type":"markdown","id":"CMofiwvW5Sd8","metadata":{"id":"CMofiwvW5Sd8"},"source":["# Submission to CMS"]},{"cell_type":"markdown","id":"n-7pww1o3iWN","metadata":{"id":"n-7pww1o3iWN"},"source":["Put your .npy files for both regression and classification tasks in the same zip file. Please name the file as `<TEAM_ID>.zip` (e.g. `123.zip`) and upload it to CMS system. It is essential that the files inside the .zip are named as follow:\n","\n","`<TEAM_ID>__<SPLIT>__reg_pred.npy` \\\n","`<TEAM_ID>__<SPLIT>__clf_pred.npy`\n","\n","Above, `<SPLIT>` should correspond to `test_public` for the leaderboard and `test_private` for the final submission.\n","As long as the `test_private.csv` data file is not released yet, the zip will contain only two files.\n"]},{"cell_type":"code","execution_count":null,"id":"B75zOG1F-KAQ","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716808592027,"user":{"displayName":"Jonas Klesen","userId":"16201315161566161330"},"user_tz":-120},"id":"B75zOG1F-KAQ"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"13b5b570","metadata":{"id":"13b5b570"},"source":[]},{"cell_type":"markdown","id":"340467b3","metadata":{"id":"340467b3"},"source":["### Appendix: Reminders about macro and micro averaging:\n","\n","When evaluating a classification model using `skm.classification_report(y_i, y_pred)` as done above, we get a macro and a weighted average.\n","\n","In the context of computing F1-score, \"macro\" and \"micro\" averaging are two commonly used techniques to aggregate the per-class F1-scores.\n","\n","**Micro-average**: Compute the F1-score globally by counting the total true positives, false negatives, and false positives over all classes, and then calculating precision, recall, and F1-score using these aggregated values.\n","\n","**Macro-average**: Calculate the F1-score for each class separately, and then take the average of these per-class F1-scores.\n","\n","The main difference between these two techniques is the way they treat class imbalance. Micro-average treats all classes equally, regardless of their size, while macro-average treats each class equally, regardless of the number of samples in that class.\n","\n","Micro-average is often used when we care about overall performance across all classes, and we want to give more weight to the performance on larger classes. In contrast, macro-average is often used when we want to evaluate the performance on each class separately and give equal weight to each class.\n","\n","\n","In addition to micro and macro averaging, there is another common technique for computing the F1-score called **weighted averaging**.\n","\n","**Weighted averaging** is similar to macro averaging in that it computes the per-class F1-score and then takes the average of these scores. However, unlike macro averaging, weighted averaging takes into account the number of samples in each class when computing the average. Specifically, the weighted average is computed as follows:\n","\n","- Compute the F1-score for each class separately.\n","- Compute the weight for each class as the number of samples in that class divided by the total number of samples.\n","- Compute the weighted average of the per-class F1-scores, where each per-class F1-score is weighted by the weight of that class.\n","\n","The weighted average is commonly used when the dataset is imbalanced, meaning that some classes have many more samples than others. In such cases, using the simple average (macro-average) would give too much weight to the smaller classes, while using micro-average would give too much weight to the larger classes. The weighted average strikes a balance between these two approaches by giving more weight to the classes with more samples while still taking into account the performance of all classes.\n"]},{"cell_type":"markdown","id":"a82d2dc3","metadata":{"id":"a82d2dc3"},"source":["When computing the F1 score for the leaderboard and the final challenge results, we will be using the macro averaging strategy."]},{"cell_type":"markdown","id":"9b8dd1b2","metadata":{"id":"9b8dd1b2"},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}
