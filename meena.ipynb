{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b16ec0d",
   "metadata": {
    "id": "8b16ec0d"
   },
   "source": [
    "# ML Course 2024 |  Medical Expenses Prediction Challenge\n",
    "\n",
    "This notebook should serve as a starting point to work on the project. Please read the project description first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a3a951",
   "metadata": {
    "id": "f6a3a951"
   },
   "source": [
    "# Set team ID\n",
    "Important: set your Team ID here. You can find it in CMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2bdc09f",
   "metadata": {
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1716808582700,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "b2bdc09f"
   },
   "outputs": [],
   "source": [
    "team_id = \"18\"  # put your team id here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wJs2YvIMvO9Q",
   "metadata": {
    "id": "wJs2YvIMvO9Q"
   },
   "source": [
    "# [Colab only] Connect to your Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "SHVae3MHvI9g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1557,
     "status": "ok",
     "timestamp": 1716808584619,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "SHVae3MHvI9g",
    "outputId": "c13669b0-1bb0-42ac-bdd5-dde5bba2485c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "UeTBTeKZvr0z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1716808584620,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "UeTBTeKZvr0z",
    "outputId": "56d405ce-0539-4c9f-e15f-1022eb3c5c7e"
   },
   "outputs": [],
   "source": [
    "# %cd \"/content/drive/MyDrive/path/to/your/project\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19af9755",
   "metadata": {
    "id": "19af9755"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UJskkHs1wW6r",
   "metadata": {
    "id": "UJskkHs1wW6r"
   },
   "source": [
    "[Colab only] Note: if you need to install any packages, run a code cell with content `!pip install packagename`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0153603",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1716808584620,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "b0153603"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "from typing import Any\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as skm\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
    "from sklearn.linear_model import (\n",
    "    LassoLars,\n",
    "    LinearRegression,\n",
    "    LogisticRegression,\n",
    "    PassiveAggressiveRegressor,\n",
    "    Ridge,\n",
    "    RidgeCV,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder,\n",
    "    OneHotEncoder,\n",
    "    PolynomialFeatures,\n",
    "    PowerTransformer,\n",
    "    QuantileTransformer,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from skopt.space import Categorical, Integer, Real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1837bdd9",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80e45379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretty_table(\n",
    "    data: list, field_names: list[str] | None = None, title: str = \"\"\n",
    ") -> PrettyTable:\n",
    "    \"\"\"Create a `PrettyTable` from the `data` list with the specified `field_names` and `title`.\"\"\"\n",
    "    table = PrettyTable()\n",
    "    if title:\n",
    "        table.title = title\n",
    "    if field_names:\n",
    "        table.field_names = field_names\n",
    "    else:\n",
    "        table.field_names = [f\"Column {i+1}\" for i in range(len(data[0]))]\n",
    "    for row in data:\n",
    "        table.add_row(row)\n",
    "    return table\n",
    "\n",
    "\n",
    "def tab_prettytable(table: PrettyTable, tabs: int) -> str:\n",
    "    \"\"\"Return the `table` as a string with `'\\\\t' * tabs` at the beginning of each line.\"\"\"\n",
    "    tabs = 0 if tabs < 0 else tabs\n",
    "    tab_str = \"\\t\" * tabs\n",
    "    table_str = str(table)\n",
    "    tabbed = tab_str + table_str.replace(\"\\n\", \"\\n\" + tab_str)\n",
    "    return tabbed\n",
    "\n",
    "\n",
    "def compute_scores(y_true: np.ndarray, y_pred: np.ndarray) -> tuple:\n",
    "    \"\"\"Returns RMSE, MAE, Median SE, Median AE, and R^2 scores for the given true and predicted\n",
    "    values, in that order.\"\"\"\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # These might also be helpful to look at. Think about why!\n",
    "    # Median Squared Error\n",
    "    medse = np.sqrt(np.median((y_true - y_pred) ** 2))\n",
    "\n",
    "    # Median Absolute Error\n",
    "    medae = np.median(abs(y_true - y_pred))\n",
    "\n",
    "    # R^2 score\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    return rmse, mae, medse, medae, r2\n",
    "\n",
    "\n",
    "def round_values(*values: Any, decimals: int = 3) -> tuple:\n",
    "    \"\"\"Return a tuple of the `values` rounded to `decimals` number of decimal places.\"\"\"\n",
    "    return tuple(round(v, decimals) for v in values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5eaed7",
   "metadata": {
    "id": "2f5eaed7"
   },
   "source": [
    "# Load Data\n",
    "\n",
    "In a first step, we load the provided training data from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc6b0bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1300,
     "status": "ok",
     "timestamp": 1716808585916,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "2fc6b0bb",
    "outputId": "98874125-e5d1-463c-9ac9-d8b04976b814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loaded dataset has 15000 rows and 110 columns\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "print(\"The loaded dataset has {} rows and {} columns\".format(df_train.shape[0], df_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c321d106",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1716808586474,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "c321d106",
    "outputId": "6628d002-66eb-420d-e59f-0969d59fe13f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RACE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PANEL</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>STUDENT_STAT</th>\n",
       "      <th>MIL_ACTIV_DUTY</th>\n",
       "      <th>HON_DISCHARGE</th>\n",
       "      <th>HEALTH_STAT</th>\n",
       "      <th>MENTAL_HLTH</th>\n",
       "      <th>CHRON_BRONCH</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PRESCR_MEDS</th>\n",
       "      <th>DIFFIC_HEAR</th>\n",
       "      <th>DIFFIC_SEE</th>\n",
       "      <th>SMOK</th>\n",
       "      <th>OVR_FEEL_14</th>\n",
       "      <th>MENTAL_HLTH_SCR</th>\n",
       "      <th>PHY_HLTH_SCR</th>\n",
       "      <th>OVR_FEEL_30</th>\n",
       "      <th>TOT_MED_EXP</th>\n",
       "      <th>UTILIZATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Non-White</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>7205.036720</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43.82</td>\n",
       "      <td>61.41</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>5501.113581</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>60.12</td>\n",
       "      <td>54.80</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>16797.708379</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>60.35</td>\n",
       "      <td>30.08</td>\n",
       "      <td>0</td>\n",
       "      <td>791</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non-White</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3605.218411</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>58.32</td>\n",
       "      <td>50.22</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-White</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>11223.127404</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>62.39</td>\n",
       "      <td>56.71</td>\n",
       "      <td>0</td>\n",
       "      <td>1264</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RACE  SEX  PANEL        WEIGHT  STUDENT_STAT  MIL_ACTIV_DUTY  \\\n",
       "0  Non-White    1     19   7205.036720            -1               2   \n",
       "1      White    1     20   5501.113581            -1               4   \n",
       "2      White    1     20  16797.708379            -1               4   \n",
       "3  Non-White    2     19   3605.218411            -1               2   \n",
       "4  Non-White    1     19  11223.127404             1               2   \n",
       "\n",
       "   HON_DISCHARGE  HEALTH_STAT  MENTAL_HLTH  CHRON_BRONCH  ...  \\\n",
       "0              2            2            2             2  ...   \n",
       "1              2            1            1             2  ...   \n",
       "2              1            3            1             2  ...   \n",
       "3              2            3            3             2  ...   \n",
       "4              2            1            2             2  ...   \n",
       "\n",
       "   NUM_PRESCR_MEDS  DIFFIC_HEAR  DIFFIC_SEE  SMOK  OVR_FEEL_14  \\\n",
       "0                0            2           2     2            1   \n",
       "1               12            2           2     2            0   \n",
       "2               20            2           2     2            0   \n",
       "3               20            2           2     2            0   \n",
       "4                3            2           2     2            0   \n",
       "\n",
       "   MENTAL_HLTH_SCR  PHY_HLTH_SCR  OVR_FEEL_30  TOT_MED_EXP  UTILIZATION  \n",
       "0            43.82         61.41            3            0          LOW  \n",
       "1            60.12         54.80            0          240          LOW  \n",
       "2            60.35         30.08            0          791          LOW  \n",
       "3            58.32         50.22            0          272          LOW  \n",
       "4            62.39         56.71            0         1264          LOW  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9633f0",
   "metadata": {
    "id": "9c9633f0"
   },
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a109e66a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1716808586474,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "a109e66a",
    "outputId": "4d758a61-6b44-48bf-ce52-3830970e0842"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: explore the data thoroughly, i.e. look for missing values, plot feature histograms, etc\n",
    "\n",
    "# This is a (rather bad) plot to get you started:\n",
    "plt.hist(df_train[\"TOT_MED_EXP\"])\n",
    "plt.title(\"Total medical expenses (train)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73924d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of             RACE  SEX  PANEL        WEIGHT  STUDENT_STAT  MIL_ACTIV_DUTY  \\\n",
       "0      Non-White    1     19   7205.036720            -1               2   \n",
       "1          White    1     20   5501.113581            -1               4   \n",
       "2          White    1     20  16797.708379            -1               4   \n",
       "3      Non-White    2     19   3605.218411            -1               2   \n",
       "4      Non-White    1     19  11223.127404             1               2   \n",
       "...          ...  ...    ...           ...           ...             ...   \n",
       "14995  Non-White    1     19  19429.034502            -1               2   \n",
       "14996  Non-White    2     19   2808.751509            -1               2   \n",
       "14997  Non-White    2     20  12237.098636            -1               2   \n",
       "14998  Non-White    2     20   5370.704372            -1               2   \n",
       "14999  Non-White    1     20   6685.613193            -1               2   \n",
       "\n",
       "       HON_DISCHARGE  HEALTH_STAT  MENTAL_HLTH  CHRON_BRONCH  ...  \\\n",
       "0                  2            2            2             2  ...   \n",
       "1                  2            1            1             2  ...   \n",
       "2                  1            3            1             2  ...   \n",
       "3                  2            3            3             2  ...   \n",
       "4                  2            1            2             2  ...   \n",
       "...              ...          ...          ...           ...  ...   \n",
       "14995              2            2            2             2  ...   \n",
       "14996              2            4            3             2  ...   \n",
       "14997              2            2            3             2  ...   \n",
       "14998              2            3            3             2  ...   \n",
       "14999              2            2            1             2  ...   \n",
       "\n",
       "       NUM_PRESCR_MEDS  DIFFIC_HEAR  DIFFIC_SEE  SMOK  OVR_FEEL_14  \\\n",
       "0                    0            2           2     2            1   \n",
       "1                   12            2           2     2            0   \n",
       "2                   20            2           2     2            0   \n",
       "3                   20            2           2     2            0   \n",
       "4                    3            2           2     2            0   \n",
       "...                ...          ...         ...   ...          ...   \n",
       "14995                0            2           2     2            0   \n",
       "14996                1            2           2     2           -9   \n",
       "14997                0            2           2     2            3   \n",
       "14998                0            2           2    -1           -1   \n",
       "14999                0            2           2     2            0   \n",
       "\n",
       "       MENTAL_HLTH_SCR  PHY_HLTH_SCR  OVR_FEEL_30  TOT_MED_EXP  UTILIZATION  \n",
       "0                43.82         61.41            3            0          LOW  \n",
       "1                60.12         54.80            0          240          LOW  \n",
       "2                60.35         30.08            0          791          LOW  \n",
       "3                58.32         50.22            0          272          LOW  \n",
       "4                62.39         56.71            0         1264          LOW  \n",
       "...                ...           ...          ...          ...          ...  \n",
       "14995            58.15         52.91            0            0          LOW  \n",
       "14996            60.29         52.11           -9            4          LOW  \n",
       "14997            22.14         67.11           10            0          LOW  \n",
       "14998            -1.00         -1.00           -1          600          LOW  \n",
       "14999            57.16         56.15            2            0          LOW  \n",
       "\n",
       "[15000 rows x 110 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16fa1a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values\n",
    "total_missing_values = df_train.isnull().sum().sum()\n",
    "print(f\"Total number of missing values: {total_missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ff115da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and target for regression and classification\n",
    "X = df_train.drop(columns=[\"TOT_MED_EXP\", \"UTILIZATION\"])\n",
    "y_regression = df_train[\"TOT_MED_EXP\"]\n",
    "y_classification = df_train[\"UTILIZATION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef4ec8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical:  ['SEX', 'PANEL', 'WEIGHT', 'STUDENT_STAT', 'MIL_ACTIV_DUTY', 'HON_DISCHARGE', 'HEALTH_STAT', 'MENTAL_HLTH', 'CHRON_BRONCH', 'JNT_PAIN', 'PREGNT', 'WALK_LIM', 'ACTIV_LIM', 'SOCIAL_LIM', 'COGNTV_LIM', 'EMPLYMT', 'REGION', 'MARITAL_STAT', 'AGE', 'POVRTY_CAT', 'INSUR_COV', 'TOT_INCOME', 'BM_IDX', 'MULT_HIGHBP', 'HOUSEWRK_LIM', 'SCHOOL_LIM', 'ADV_NO_FAT_FOOD', 'ADV_EXERCISE_MORE', 'ADV_DNTL_CKP', 'FREQ_DNTL_CKP', 'RSN_NO_DNTL_CKP', 'RSN_NO_MED_CKP', 'EMPLYR_INS', 'DOC_CK_BP', 'TAKE_RISK', 'NUM_DEP_OUT_REP_UNT', 'ADV_BOOST_SEAT', 'WHEN_ADV_BOOST_SEAT', 'FEEL_DEPRS', 'ADV_NO_SMKG', 'AGE_DIAG_ADHD', 'CHILD_SUPP', 'PROB_WKIDS', 'PROB_WBHV', 'WEAR_SEATBLT', 'PUB_ASST', 'EDU_DEG', 'SPOUSE_PRSNT', 'TAX_FORM_TYP', 'FOOD_STMP_MNTHS', 'FOOD_STMP_VAL', 'WHEN_ADV_LAP_BLT', 'EDU_YRS', 'WHEN_LST_ASTHMA', 'FAM_INCOME', 'DELAY_PRESCR_MED', 'ADV_LAP_BLT', 'ADV_EAT_HLTHY', 'DOC_TIM_ALN', 'POVRTY_LEV', 'APPT_REG_MEDCARE', 'LOST_ALL_TEETH', 'PROB_BILL_PAY', 'ASPRN_REG', 'OCCUP', 'DIFF_ERRND_ALN', 'DIAB_KIDNY', 'DIAB_INSLN', 'DIAB_MED', 'DISPSN_STAT', 'TIME_LAST_PSA', 'DAYS_CAREOTHR_NOWORK', 'WHEN_ADV_EXERCISE', 'UNION_STAT', 'DEAF', 'BLIND', 'LAST_FLU_VAC', 'NON_ENG_LANG', 'UNABL_PRES_MED', 'HEAR_AID', 'PENSN_PLAN', 'LAST_REG_CKP', 'NO_WORK_WHY', 'DAYS_ILL_NOWORK', 'DAYS_ILL_NOSCHL', 'HIGH_BP_DIAG', 'COR_HRT_DIAG', 'ANGINA_DIAG', 'HRT_ATT_DIAG', 'OTH_HRT_DIAG', 'STROKE_DIAG', 'EMPHYM_DIAG', 'HIGHCHOL_DIAG', 'CANCER_DIAG', 'DIAB_DIAG', 'ARTHR_DIAG', 'ARTHR_TYPE', 'ASTHM_DIAG', 'ADHD_DIAG', 'NUM_PRESCR_MEDS', 'DIFFIC_HEAR', 'DIFFIC_SEE', 'SMOK', 'OVR_FEEL_14', 'MENTAL_HLTH_SCR', 'PHY_HLTH_SCR', 'OVR_FEEL_30']\n",
      "Categorical:  ['RACE']\n"
     ]
    }
   ],
   "source": [
    "# here, identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "# categorical_cols.remove(\"RACE\")  # Exclude 'RACE' from categorical columns\n",
    "\n",
    "print(\"Numerical: \", numerical_cols)\n",
    "print(\"Categorical: \", categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2323d4",
   "metadata": {
    "id": "9c2323d4"
   },
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GjxnefI-aSOZ",
   "metadata": {
    "id": "GjxnefI-aSOZ"
   },
   "source": [
    "In this part, we will solve an linear regression task to predict our target `TOT_MED_EXP`, i.e. total medical expences, using the other features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2_CBqwiigmaF",
   "metadata": {
    "id": "2_CBqwiigmaF"
   },
   "source": [
    "In its simplest form, predictions of a linear regression model can be summarized as\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\mathbf{w}^T \\mathbf{x} = f(\\mathbf{x},\\mathbf{w})\n",
    "$$\n",
    "\n",
    "which can be optimized using the cost function\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^{*}=\\underset{\\mathbf{w}}{\\arg \\min } \\frac{1}{n} \\sum_{i=1}^{n}\\left(y_{i}-f\\left(\\mathbf{x}_{i}, \\mathbf{w}\\right)\\right)^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f878db27",
   "metadata": {
    "id": "f878db27"
   },
   "source": [
    "### Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "JzZwQFApeUBd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1716808586474,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "JzZwQFApeUBd",
    "outputId": "63b1cb7d-ff8e-4842-fe8e-11de1153838b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset now has 15000 rows and 108 columns\n"
     ]
    }
   ],
   "source": [
    "# Filter out non-positive values from both X and y_regression\n",
    "# TODO: We gotta deal with the 0 values in the target variable\n",
    "# mask = y_regression > 0\n",
    "\n",
    "# X = X[mask]\n",
    "# y_regression = y_regression[mask]\n",
    "\n",
    "print(\"The dataset now has {} rows and {} columns\".format(X.shape[0], X.shape[1]))\n",
    "\n",
    "# Split X and y for training and validation purposes\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_regression, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464b2bd9",
   "metadata": {
    "id": "464b2bd9"
   },
   "source": [
    "### Train a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e110780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_param_grids_for(model_name: str, grid_search_type: str) -> dict:\n",
    "    \"\"\"Get the parameter grid for the specified model and grid search type.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : Any\n",
    "        The name of the model to get the parameter grid for.\n",
    "    grid_search_type : str\n",
    "        The type of grid search to get the parameter grid for.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The parameter grid for the specified model and grid search type.\n",
    "    \"\"\"\n",
    "    param_grids = {\n",
    "        \"LinearRegression\": {\n",
    "            \"grid\": {\"fit_intercept\": [True, False]},\n",
    "            \"bayes\": {\"fit_intercept\": Categorical([True, False])},\n",
    "        },\n",
    "        \"Ridge\": {\n",
    "            \"grid\": {\n",
    "                \"alpha\": [0.0005, 0.1, 1.0, 10.0],\n",
    "                \"fit_intercept\": [True, False],\n",
    "            },\n",
    "            \"bayes\": {\n",
    "                \"alpha\": Real(0.0001, 100, prior=\"log-uniform\"),\n",
    "                \"fit_intercept\": Categorical([True, False]),\n",
    "            },\n",
    "        },\n",
    "        \"Lasso\": {\n",
    "            \"grid\": {\n",
    "                \"alpha\": [0.0005, 0.1, 1.0, 10.0],\n",
    "                \"fit_intercept\": [True, False],\n",
    "            },\n",
    "            \"bayes\": {\n",
    "                \"alpha\": Real(0.0001, 100, prior=\"log-uniform\"),\n",
    "                \"fit_intercept\": Categorical([True, False]),\n",
    "            },\n",
    "        },\n",
    "        \"LassoLars\": {\n",
    "            \"grid\": {\n",
    "                \"alpha\": [0.0005, 0.1, 1.0, 10.0],\n",
    "                \"fit_intercept\": [True, False],\n",
    "                \"positive\": [True, False],\n",
    "                \"jitter\": [0.01, 0.1, 0.5],\n",
    "            },\n",
    "            \"bayes\": {\n",
    "                \"alpha\": Real(0.0001, 100, prior=\"log-uniform\"),\n",
    "                \"fit_intercept\": Categorical([True, False]),\n",
    "            },\n",
    "        },\n",
    "        \"KernelRidge\": {\n",
    "            \"grid\": {\n",
    "                \"alpha\": [0.0005, 0.1, 1.0, 10.0],\n",
    "                \"kernel\": [\"linear\", \"poly\", \"rbf\"],\n",
    "                \"degree\": [2, 3],\n",
    "                \"gamma\": [\"scale\", \"auto\"],\n",
    "            },\n",
    "            \"bayes\": {\n",
    "                \"alpha\": Real(0.0001, 100, prior=\"log-uniform\"),\n",
    "                \"kernel\": Categorical([\"linear\", \"poly\", \"rbf\"]),\n",
    "                \"degree\": Integer(2, 3),\n",
    "                \"gamma\": Categorical([\"scale\", \"auto\"]),\n",
    "            },\n",
    "        },\n",
    "        \"TweedieRegressor\": {\n",
    "            \"grid\": {\n",
    "                \"power\": np.linspace(1.0, 2.0, 10),\n",
    "                \"alpha\": np.logspace(-3, 1, 10),\n",
    "                \"link\": [\"log\", \"identity\"],\n",
    "                \"max_iter\": [5000],\n",
    "            },\n",
    "            \"bayes\": {\n",
    "                \"power\": Real(1.0, 2.0),\n",
    "                \"alpha\": Real(1e-3, 10, prior=\"log-uniform\"),\n",
    "                \"link\": Categorical([\"log\", \"identity\"]),\n",
    "                \"max_iter\": Categorical([5000]),\n",
    "            },\n",
    "        },\n",
    "        \"LGBMRegressor\": {\n",
    "            \"grid\": {\n",
    "                \"num_leaves\": [31, 127],\n",
    "                \"learning_rate\": [0.01, 0.1],\n",
    "                \"n_estimators\": [20, 40],\n",
    "            },\n",
    "            \"bayes\": {\n",
    "                \"num_leaves\": Integer(31, 127),\n",
    "                \"learning_rate\": Real(0.01, 0.1, prior=\"log-uniform\"),\n",
    "                \"n_estimators\": Integer(20, 40),\n",
    "            },\n",
    "        },\n",
    "        \"GammaRegressor\": {\n",
    "            \"grid\": {\n",
    "                \"alpha\": np.linspace(0.000001, 1, 10),\n",
    "                \"fit_intercept\": [True, False],\n",
    "                \"solver\": [\"lbfgs\", \"newton-cholesky\"],\n",
    "                \"max_iter\": [1000, 5000],\n",
    "            },\n",
    "            \"bayes\": {\n",
    "                \"alpha\": Real(0.000001, 1, prior=\"log-uniform\"),\n",
    "                \"fit_intercept\": Categorical([True, False]),\n",
    "                \"solver\": Categorical([\"lbfgs\", \"newton-cholesky\"]),\n",
    "                \"max_iter\": Categorical([1000, 5000]),\n",
    "            },\n",
    "        },\n",
    "        \"PoissonRegressor\": {\n",
    "            \"grid\": {\n",
    "                \"alpha\": np.logspace(-3, 1, 10),\n",
    "                \"fit_intercept\": [True, False],\n",
    "            },\n",
    "            \"bayes\": {\n",
    "                \"alpha\": Real(1e-3, 10, prior=\"log-uniform\"),\n",
    "                \"fit_intercept\": Categorical([True, False]),\n",
    "            },\n",
    "        },\n",
    "        \"PassiveAggressiveRegressor\": {\n",
    "            \"grid\": {\n",
    "                \"C\": [0.1, 1, 10, 100, 1000, 100000],\n",
    "                \"fit_intercept\": [True, False],\n",
    "                \"max_iter\": [1000, 5000],\n",
    "                \"loss\": [\"epsilon_insensitive\", \"squared_epsilon_insensitive\"],\n",
    "            },\n",
    "            \"bayes\": {\n",
    "                \"C\": Real(0.1, 100000, prior=\"log-uniform\"),\n",
    "                \"fit_intercept\": Categorical([True, False]),\n",
    "                \"max_iter\": Categorical([1000, 5000]),\n",
    "                \"loss\": Categorical([\"epsilon_insensitive\", \"squared_epsilon_insensitive\"]),\n",
    "            },\n",
    "        },\n",
    "        \"GradientBoostingRegressor\": {\n",
    "            \"grid\": {\n",
    "                \"n_estimators\": [100, 200, 300],\n",
    "                \"learning_rate\": [0.01, 0.1],\n",
    "                \"max_depth\": [3, 5, 7],\n",
    "            },\n",
    "            \"bayes\": {\n",
    "                \"n_estimators\": Integer(100, 300),\n",
    "                \"learning_rate\": Real(0.01, 0.1, prior=\"log-uniform\"),\n",
    "                \"max_depth\": Integer(3, 7),\n",
    "            },\n",
    "        },\n",
    "        \"SVR\": {\n",
    "            \"grid\": {\n",
    "                \"C\": [0.01, 0.1, 0.5, 1, 10, 100],\n",
    "                \"kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "                \"gamma\": [0.01, 0.05, 0.1, 1, \"scale\", \"auto\"],\n",
    "            },\n",
    "            \"bayes\": {\n",
    "                \"C\": Real(0.1, 10, prior=\"log-uniform\"),\n",
    "                \"gamma\": Real(0.01, 0.1, prior=\"log-uniform\"),\n",
    "                \"kernel\": Categorical([\"linear\", \"rbf\", \"poly\"]),\n",
    "                \"degree\": Integer(2, 3),\n",
    "            },\n",
    "        },\n",
    "        \"LinearSVR\": {\n",
    "            \"grid\": {\n",
    "                \"C\": [0.1, 0.5, 1, 5, 10],\n",
    "                \"intercept_scaling\": [1, 10],\n",
    "                \"epsilon\": [0.0, 0.1, 0.2, 0.5],\n",
    "                \"tol\": [1e-4, 1e-3, 1e-2],\n",
    "                \"C\": [0.1, 1.0, 10.0],\n",
    "                \"loss\": [\"epsilon_insensitive\", \"squared_epsilon_insensitive\"],\n",
    "                \"fit_intercept\": [True, False],\n",
    "                \"dual\": [True, False],\n",
    "                \"max_iter\": [1000, 2000, 5000],\n",
    "            },\n",
    "            \"bayes\": {\n",
    "                \"C\": Real(0.1, 10, prior=\"log-uniform\"),\n",
    "                \"intercept_scaling\": Integer(1, 10),\n",
    "                \"epsilon\": Real(0.0, 1.0, prior=\"uniform\"),\n",
    "                \"tol\": Real(1e-4, 1e-1, prior=\"log-uniform\"),\n",
    "                \"loss\": Categorical([\"epsilon_insensitive\", \"squared_epsilon_insensitive\"]),\n",
    "                \"fit_intercept\": Categorical([True, False]),\n",
    "                \"dual\": Categorical([True, False]),\n",
    "                \"max_iter\": Integer(1000, 5000),\n",
    "            },\n",
    "        },\n",
    "        \"LogisticRegression\": {\n",
    "            \"grid\": {\n",
    "                \"C\": [0.1, 1, 10, 100],\n",
    "                \"penalty\": [\"l1\", \"l2\"],\n",
    "                \"fit_intercept\": [True, False],\n",
    "            },\n",
    "            \"bayes\": {\n",
    "                \"C\": Real(0.1, 100, prior=\"log-uniform\"),\n",
    "                \"penalty\": Categorical([\"l1\", \"l2\"]),\n",
    "                \"fit_intercept\": Categorical([True, False]),\n",
    "            },\n",
    "        },\n",
    "        \"LGBMClassifier\": {\n",
    "            \"grid\": {\n",
    "                \"num_leaves\": [31, 127],\n",
    "                \"learning_rate\": [0.01, 0.1],\n",
    "                \"n_estimators\": [20, 40],\n",
    "            },\n",
    "            \"bayes\": {\n",
    "                \"num_leaves\": Integer(31, 127),\n",
    "                \"learning_rate\": Real(0.01, 0.1, prior=\"log-uniform\"),\n",
    "                \"n_estimators\": Integer(20, 40),\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    if model_name not in param_grids:\n",
    "        raise ValueError(f\"Model {model_name} not found in param_grids.py\")\n",
    "    if grid_search_type not in param_grids[model_name]:\n",
    "        raise ValueError(f\"Grid search type {grid_search_type} not found for model {model_name}\")\n",
    "\n",
    "    return param_grids.get(model_name, {}).get(grid_search_type, None)\n",
    "\n",
    "\n",
    "def choose_param_grid(model: Any, grid_search_type: str, add_str_to_keys=None) -> dict:\n",
    "    \"\"\"Choose a suitable hyperparameter grid to use with `GridSearchCV` or similar object based on\n",
    "    the model class and the `grid_search_type` to be performed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Any\n",
    "        The model object to get the hyperparameter grid for. It should be a valid scikit-learn or\n",
    "        cuML model object.\n",
    "    grid_search_type : str\n",
    "        The type of grid search to perform. It should be either 'grid' or 'bayes'.\n",
    "    add_str_to_keys : str, optional\n",
    "        A string to add to the beginning of each key in the parameter grid, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The hyperparameter grid for the specified model and grid search type\n",
    "    \"\"\"\n",
    "    model_name = model.__class__.__name__\n",
    "    param_grid = available_param_grids_for(model_name, grid_search_type)\n",
    "\n",
    "    if add_str_to_keys is not None:\n",
    "        rewritten_param_grid = {}\n",
    "        if add_str_to_keys[-2:] == \"__\":\n",
    "            add_str_to_keys = add_str_to_keys[:-2]\n",
    "\n",
    "        if isinstance(param_grid, dict):\n",
    "            for param, value in param_grid.items():\n",
    "                rewritten_param_grid[f\"{add_str_to_keys}__{param}\"] = value\n",
    "        elif isinstance(param_grid, list):\n",
    "            rewritten_param_grid = []\n",
    "            for param_dict in param_grid:\n",
    "                new_param_dict = {f\"{add_str_to_keys}__{k}\": v for k, v in param_dict.items()}\n",
    "                rewritten_param_grid.append(new_param_dict)\n",
    "        param_grid = rewritten_param_grid\n",
    "\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8be7dc9",
   "metadata": {
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1716808586873,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "e8be7dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following hyperparameter grid for LassoLars():\n",
      "\tregression__alpha: [0.0005, 0.1, 1.0, 10.0]\n",
      "\tregression__fit_intercept: [True, False]\n",
      "\tregression__positive: [True, False]\n",
      "\tregression__jitter: [0.01, 0.1, 0.5]\n",
      "\tselect__k: [10]\n",
      "\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best hyperparameters found:  {'regression__alpha': 10.0, 'regression__fit_intercept': True, 'regression__jitter': 0.01, 'regression__positive': False, 'select__k': 10}\n"
     ]
    }
   ],
   "source": [
    "# Feature selection for linear regression\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"preprocessor\",\n",
    "            ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"num\", StandardScaler(), numerical_cols),\n",
    "                    (\"cat\", OneHotEncoder(drop=\"first\"), categorical_cols),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        (\"poly\", PolynomialFeatures(degree=2)),\n",
    "        (\"select\", SelectKBest(score_func=f_regression)),\n",
    "        (\"regression\", LassoLars()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = choose_param_grid(\n",
    "    pipeline.named_steps[\"regression\"], \"grid\", add_str_to_keys=\"regression\"\n",
    ")\n",
    "\n",
    "# Add the number of features to select to the hyperparameter grid\n",
    "param_grid[\"select__k\"] = [10]  # Number of top features to select for regression\n",
    "\n",
    "print(f\"Using the following hyperparameter grid for {pipeline.named_steps['regression']}:\")\n",
    "for key, value in param_grid.items():\n",
    "    print(f\"\\t{key}: {value}\")\n",
    "\n",
    "print()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    refit=\"neg_root_mean_squared_error\",\n",
    "    scoring={\n",
    "        \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "        \"neg_median_absolute_error\": \"neg_median_absolute_error\",\n",
    "        \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
    "    },\n",
    "    n_jobs=-2,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best hyperparameters found: \", grid_search.best_params_)\n",
    "\n",
    "# This won't work if using PCA or Polynomial features before SelectKBest\n",
    "# print(\n",
    "#     \"Selected features for linear regression:\",\n",
    "#     X.columns[grid_search.best_estimator_.named_steps[\"select\"].get_support(indices=True)],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61545555",
   "metadata": {},
   "source": [
    "### Train a model with a `y` transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73666657",
   "metadata": {},
   "source": [
    "See: https://scikit-learn.org/dev/auto_examples/compose/plot_transformed_target.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6b140e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meenu\\AppData\\Local\\Temp\\ipykernel_7912\\3581623490.py:24: UserWarning: The figure layout has changed to tight\n",
      "  f.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import quantile_transform\n",
    "\n",
    "y_trans = quantile_transform(\n",
    "    y_regression.to_frame(), n_quantiles=900, output_distribution=\"normal\", copy=True\n",
    ").squeeze()\n",
    "\n",
    "y_trans = (\n",
    "    PowerTransformer(method=\"yeo-johnson\", standardize=False)\n",
    "    .fit_transform(y_regression.to_frame())\n",
    "    .squeeze()\n",
    ")\n",
    "\n",
    "f, (ax0, ax1) = plt.subplots(1, 2, constrained_layout=True, figsize=(12, 6))\n",
    "\n",
    "ax0.hist(y_regression, bins=100, density=True)\n",
    "ax0.set_ylabel(\"Probability\")\n",
    "ax0.set_xlabel(\"Target\")\n",
    "ax0.set_title(\"Target distribution\")\n",
    "\n",
    "ax1.hist(y_trans, bins=100, density=True)\n",
    "ax1.set_ylabel(\"Probability\")\n",
    "ax1.set_xlabel(\"Target\")\n",
    "ax1.set_title(\"Transformed target distribution\")\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65b0e739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following hyperparameter grid for TransformedTargetRegressor(regressor=LassoLars(),\n",
      "                           transformer=PowerTransformer()):\n",
      "\tregression__regressor__alpha: [0.0005, 0.1, 1.0, 10.0]\n",
      "\tregression__regressor__fit_intercept: [True, False]\n",
      "\tregression__regressor__positive: [True, False]\n",
      "\tregression__regressor__jitter: [0.01, 0.1, 0.5]\n",
      "\tselect__k: [40, 80]\n",
      "\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best hyperparameters found:  {'regression__regressor__alpha': 0.1, 'regression__regressor__fit_intercept': True, 'regression__regressor__jitter': 0.1, 'regression__regressor__positive': False, 'select__k': 80}\n"
     ]
    }
   ],
   "source": [
    "# Feature selection for linear regression\n",
    "pipeline_y_transformed = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"preprocessor\",\n",
    "            ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"num\", StandardScaler(), numerical_cols),\n",
    "                    (\"cat\", OneHotEncoder(drop=\"first\"), categorical_cols),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        (\"poly\", PolynomialFeatures(degree=2)),\n",
    "        (\"select\", SelectKBest(score_func=f_regression)),\n",
    "        (\n",
    "            \"regression\",\n",
    "            # TransformedTargetRegressor(\n",
    "            #     regressor=LinearRegression(), func=np.log1p, inverse_func=np.expm1\n",
    "            # ),\n",
    "            # TransformedTargetRegressor(\n",
    "            #     regressor=LassoLars(),\n",
    "            #     transformer=QuantileTransformer(n_quantiles=900, output_distribution=\"normal\"),\n",
    "            # ),\n",
    "            TransformedTargetRegressor(\n",
    "                regressor=LassoLars(),\n",
    "                transformer=PowerTransformer(method=\"yeo-johnson\"),\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = choose_param_grid(\n",
    "    pipeline_y_transformed.named_steps[\"regression\"].regressor,\n",
    "    \"grid\",\n",
    "    add_str_to_keys=\"regression__regressor\",\n",
    ")\n",
    "\n",
    "# Add the number of features to select to the hyperparameter grid\n",
    "param_grid[\"select__k\"] = [40, 80]  # Number of top features to select for regression\n",
    "\n",
    "print(\n",
    "    f\"Using the following hyperparameter grid for {pipeline_y_transformed.named_steps['regression']}:\"\n",
    ")\n",
    "for key, value in param_grid.items():\n",
    "    print(f\"\\t{key}: {value}\")\n",
    "\n",
    "print()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_y_transformed,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    refit=\"neg_root_mean_squared_error\",\n",
    "    scoring={\n",
    "        \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "        \"neg_median_absolute_error\": \"neg_median_absolute_error\",\n",
    "        \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
    "    },\n",
    "    n_jobs=-2,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "print(\"Best hyperparameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Get the best estimator\n",
    "best_estimator_y_transformed = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TarmeeGneDFb",
   "metadata": {
    "id": "TarmeeGneDFb"
   },
   "source": [
    "### Evaluate the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dba9ff00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1716808828969,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "dba9ff00",
    "outputId": "a508ea65-c71f-4a67-b665-647c5a88e169"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PredictionErrorDisplay\n\u001b[1;32m----> 3\u001b[0m regressor_name \u001b[38;5;241m=\u001b[39m best_estimator\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m      5\u001b[0m datasets \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining data\u001b[39m\u001b[38;5;124m\"\u001b[39m: [X_train_reg, y_train_reg],\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation data\u001b[39m\u001b[38;5;124m\"\u001b[39m: [X_test_reg, y_test_reg],\n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m     10\u001b[0m rows \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# For a PrettyTable\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_estimator' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import PredictionErrorDisplay\n",
    "\n",
    "regressor_name = best_estimator.named_steps[\"regression\"].__class__.__name__\n",
    "\n",
    "datasets = {\n",
    "    \"Training data\": [X_train_reg, y_train_reg],\n",
    "    \"Validation data\": [X_test_reg, y_test_reg],\n",
    "}\n",
    "\n",
    "rows = []  # For a PrettyTable\n",
    "for split_name, dataset in datasets.items():\n",
    "    X_i, y_i = dataset\n",
    "    y_pred = best_estimator.predict(X_i)\n",
    "    y_pred_transformed = best_estimator_y_transformed.predict(X_i)\n",
    "\n",
    "    # Compute the regression metrics\n",
    "    rmse, mae, medse, medae, r2 = compute_scores(y_i, y_pred)\n",
    "    rmse_transformed, mae_transformed, medse_transformed, medae_transformed, r2_transformed = (\n",
    "        compute_scores(y_i, y_pred_transformed)\n",
    "    )\n",
    "\n",
    "    # Round them to 3 decimal places\n",
    "    rmse, mae, medse, medae, r2 = round_values(rmse, mae, medse, medae, r2)\n",
    "    rmse_transformed, mae_transformed, medse_transformed, medae_transformed, r2_transformed = (\n",
    "        round_values(\n",
    "            rmse_transformed, mae_transformed, medse_transformed, medae_transformed, r2_transformed\n",
    "        )\n",
    "    )\n",
    "\n",
    "    f, (ax0, ax1) = plt.subplots(2, 2, sharey=\"row\", figsize=(10, 8), constrained_layout=True)\n",
    "\n",
    "    # plot the actual vs predicted values\n",
    "    PredictionErrorDisplay.from_predictions(\n",
    "        y_i,\n",
    "        y_pred,\n",
    "        kind=\"actual_vs_predicted\",\n",
    "        ax=ax0[0],\n",
    "        scatter_kwargs={\"alpha\": 0.5},\n",
    "    )\n",
    "    PredictionErrorDisplay.from_predictions(\n",
    "        y_i,\n",
    "        y_pred_transformed,\n",
    "        kind=\"actual_vs_predicted\",\n",
    "        ax=ax0[1],\n",
    "        scatter_kwargs={\"alpha\": 0.5},\n",
    "    )\n",
    "\n",
    "    # Add the score in the legend of each axis\n",
    "    for ax, scores in zip(\n",
    "        [ax0[0], ax0[1]], [[rmse, mae, r2], [rmse_transformed, mae_transformed, r2_transformed]]\n",
    "    ):\n",
    "        for name, score in zip([\"RMSE\", \"MAE\", \"$R^2$\"], scores):\n",
    "            ax.plot([], [], \" \", label=f\"{name} = {score}\")\n",
    "        ax.legend(loc=\"upper left\")\n",
    "\n",
    "    ax0[0].set_title(f\"{regressor_name}\")\n",
    "    ax0[1].set_title(f\"{regressor_name}\\nWith $y$ transformed\")\n",
    "    ax0[0].set_xlabel(\"\")\n",
    "    ax0[1].set_xlabel(\"\")\n",
    "\n",
    "    # plot the residuals vs the predicted values\n",
    "    PredictionErrorDisplay.from_predictions(\n",
    "        y_i,\n",
    "        y_pred,\n",
    "        kind=\"residual_vs_predicted\",\n",
    "        ax=ax1[0],\n",
    "        scatter_kwargs={\"alpha\": 0.5},\n",
    "    )\n",
    "    PredictionErrorDisplay.from_predictions(\n",
    "        y_i,\n",
    "        y_pred_transformed,\n",
    "        kind=\"residual_vs_predicted\",\n",
    "        ax=ax1[1],\n",
    "        scatter_kwargs={\"alpha\": 0.5},\n",
    "    )\n",
    "    ax1[1].set_ylabel(\"\")\n",
    "\n",
    "    plt.suptitle(f\"Regression metrics for {regressor_name} on {split_name.capitalize()}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    rows.append([split_name, rmse, mae, medse, medae, r2])\n",
    "    rows.append(\n",
    "        [\n",
    "            \" (y-transformed)\",\n",
    "            rmse_transformed,\n",
    "            mae_transformed,\n",
    "            medse_transformed,\n",
    "            medae_transformed,\n",
    "            r2_transformed,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "print(\n",
    "    make_pretty_table(rows, title=\"Regression metrics\", field_names=[\"Split\", \"RMSE\", \"MAE\", \"MedSE\", \"MedAE\", \"R^2\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5818dbc4",
   "metadata": {
    "id": "5818dbc4"
   },
   "source": [
    "### Export test set predictions for regression task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qBItenN5erIi",
   "metadata": {
    "id": "qBItenN5erIi"
   },
   "source": [
    "At this point, we can use our model to predict the medical expenses from the test sets. The following cell shows an example on how to do this.\n",
    "\n",
    "You must save your predictions (`y_hat`) to a file and name the file in the following format:\n",
    "\n",
    "`<TEAM_ID>__<SPLIT>__reg_pred.npy`\n",
    "\n",
    "Make sure that:\n",
    "\n",
    "`<TEAM_ID>` is your team id as given in CMS.\n",
    "\n",
    "`<SPLIT>` is \"test_public\" during the semester and \"test_private\" for the final submission. We will write an announcement to CMS once the test_private dataset is available to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91ee5e03",
   "metadata": {
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1716808940546,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "91ee5e03"
   },
   "outputs": [],
   "source": [
    "# Run this to save a file with your predictions on the test set to be submitted\n",
    "# Specify the dataset split\n",
    "split = \"test_public\"  # Replace by 'test_private' for FINAL submission\n",
    "\n",
    "# Load the test data\n",
    "df_test = pd.read_csv(f\"data/{split}.csv\")\n",
    "\n",
    "y_hat = best_estimator.predict(df_test)\n",
    "\n",
    "# Save the results with the format <TEAM_ID>__<SPLIT>__reg_pred.npy\n",
    "folder = \"./results\"\n",
    "np.save(\n",
    "    os.path.join(folder, f\"{team_id}__{split}__reg_pred.npy\"), y_hat\n",
    ")  # Note the double underscores '__' in the filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34410538",
   "metadata": {
    "id": "34410538"
   },
   "source": [
    "# Linear classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WeqFeth6hb6w",
   "metadata": {
    "id": "WeqFeth6hb6w"
   },
   "source": [
    "In this part, we will train a simple linear classification model to predict our target `UTILIZATION`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1a46f9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m k_classification \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m  \u001b[38;5;66;03m# Number of top features to select for classification\u001b[39;00m\n\u001b[0;32m      2\u001b[0m select_k_best_classification \u001b[38;5;241m=\u001b[39m SelectKBest(score_func\u001b[38;5;241m=\u001b[39mchi2, k\u001b[38;5;241m=\u001b[39mk_classification)\n\u001b[0;32m      3\u001b[0m X_classification_selected \u001b[38;5;241m=\u001b[39m select_k_best_classification\u001b[38;5;241m.\u001b[39mfit_transform(\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mX_processed\u001b[49m, y_classification\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m selected_features_classification \u001b[38;5;241m=\u001b[39m select_k_best_classification\u001b[38;5;241m.\u001b[39mget_support(indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_processed' is not defined"
     ]
    }
   ],
   "source": [
    "k_classification = 20  # Number of top features to select for classification\n",
    "select_k_best_classification = SelectKBest(score_func=chi2, k=k_classification)\n",
    "X_classification_selected = select_k_best_classification.fit_transform(\n",
    "    X_processed, y_classification\n",
    ")\n",
    "selected_features_classification = select_k_best_classification.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_QIyfxXthmTT",
   "metadata": {
    "id": "_QIyfxXthmTT"
   },
   "source": [
    "We will first change our targets (classes: LOW, HIGH) to numeric targets. Then, we solve a logistic regression problem by minimizing the binary cross-entropy function\n",
    "\n",
    "$$\n",
    "J(\\theta) = -\\frac{1}{n} \\sum_{i=1}^{n} \\left( y_i \\log(p_{\\theta}(\\hat{y}=1 | \\mathbf{x}_i)) + (1 - y_i) \\log(p_{\\theta}(\\hat{y}=0 | \\mathbf{x}_i)) \\right)\n",
    "$$\n",
    "\n",
    "where $y_i \\in \\{0, 1\\}$ and $p_{\\theta}(\\hat{y}=k | \\mathbf{x}_i)$ is the probability assigned by our model to class $k$ having observed features $\\mathbf{x}_i$.\n",
    "\n",
    "0 refers to HIGH, and 1 refers to LOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d08d2d",
   "metadata": {
    "id": "f6d08d2d"
   },
   "source": [
    "### Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f516bc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1716809033654,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "5f516bc9",
    "outputId": "277dbcdf-5798-4312-a723-3d1ae52645c6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m df_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTILIZATION\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      5\u001b[0m df_train\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTILIZATION\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTOT_MED_EXP\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 7\u001b[0m le \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessing\u001b[49m\u001b[38;5;241m.\u001b[39mLabelEncoder()\n\u001b[0;32m      8\u001b[0m df_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRACE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(df_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRACE\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     10\u001b[0m y \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(y)  \u001b[38;5;66;03m# maps HIGH to 0 and LOW to 1\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(f\"data/train.csv\")\n",
    "\n",
    "y = df_train[\"UTILIZATION\"]\n",
    "\n",
    "df_train.drop(columns=[\"UTILIZATION\", \"TOT_MED_EXP\"])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_test[\"RACE\"] = le.fit_transform(df_test[\"RACE\"])\n",
    "\n",
    "y = le.fit_transform(y)  # maps HIGH to 0 and LOW to 1\n",
    "\n",
    "print(f\"Original classes {le.classes_}\")\n",
    "print(f\"Corresponding numeric classes {le.transform(le.classes_)}\")\n",
    "\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\", f\", unique entries in y: {np.unique(y)}\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# These hyperparameters are just placeholders, choosen without much care. For a good LogisticRegression baseline, play with them a bit.\n",
    "clf = linear_model.LogisticRegression(\n",
    "    penalty=None,\n",
    "    dual=False,\n",
    "    tol=0.0001,\n",
    "    C=1.0,\n",
    "    fit_intercept=True,\n",
    "    intercept_scaling=1,\n",
    "    class_weight=None,  # None, balanced\n",
    "    random_state=None,\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=1500,\n",
    "    multi_class=\"auto\",\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    n_jobs=None,\n",
    "    l1_ratio=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0S5pf_bA2XAV",
   "metadata": {
    "id": "0S5pf_bA2XAV"
   },
   "source": [
    "### Fit the model by using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167c0b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4083,
     "status": "ok",
     "timestamp": 1716809070913,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "c167c0b4",
    "outputId": "b6c6a051-fc21-42d1-ab55-cd4dd453eddc"
   },
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "URLzKp2J2x6i",
   "metadata": {
    "id": "URLzKp2J2x6i"
   },
   "source": [
    "Now evaluate your model. Check the appendix for details on micro, macro and weighted averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e0e50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1716809077809,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "ff8e0e50",
    "outputId": "faa68cba-35cf-4203-c592-4879fdb63226"
   },
   "outputs": [],
   "source": [
    "datasets = {\"training data\": [X_train, y_train], \"validation data\": [X_val, y_val]}\n",
    "\n",
    "for split_name, dataset in datasets.items():\n",
    "    X_i, y_i = dataset\n",
    "    y_pred = clf.predict(X_i)\n",
    "    print(f\"\\nSplit: {split_name}\")\n",
    "\n",
    "    print(skm.classification_report(y_i, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sGxdMSXO2-xH",
   "metadata": {
    "id": "sGxdMSXO2-xH"
   },
   "source": [
    "At this point, we can use our model to predict healthcare utilization on the test set.\n",
    "\n",
    "We again need to follow a specific namim format when saving the predictions. Similarly to before, the name of the file should be `<TEAM_ID>__<SPLIT>__clf_pred.npy`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cea870",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1716808592027,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "d0cea870"
   },
   "outputs": [],
   "source": [
    "# Run this to save a file with your predictions on the test set to be submitted\n",
    "\n",
    "split = \"test_public\"  # replace by 'test_private' for FINAL submission\n",
    "\n",
    "df_test = pd.read_csv(f\"data/{split}.csv\")\n",
    "\n",
    "# Process data\n",
    "df_test[\"RACE\"] = LabelEncoder().fit_transform(df_test[\"RACE\"])\n",
    "\n",
    "y_hat = clf.predict(df_test)\n",
    "\n",
    "# Save the results with the format <TEAM_ID>__<SPLIT>__clf_pred.npy\n",
    "\n",
    "folder = \"./\"\n",
    "np.save(os.path.join(folder, f\"{team_id}__{split}__clf_pred.npy\"), y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CMofiwvW5Sd8",
   "metadata": {
    "id": "CMofiwvW5Sd8"
   },
   "source": [
    "# Submission to CMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n-7pww1o3iWN",
   "metadata": {
    "id": "n-7pww1o3iWN"
   },
   "source": [
    "Put your .npy files for both regression and classification tasks in the same zip file. Please name the file as `<TEAM_ID>.zip` (e.g. `123.zip`) and upload it to CMS system. It is essential that the files inside the .zip are named as follow:\n",
    "\n",
    "`<TEAM_ID>__<SPLIT>__reg_pred.npy` \\\n",
    "`<TEAM_ID>__<SPLIT>__clf_pred.npy`\n",
    "\n",
    "Above, `<SPLIT>` should correspond to `test_public` for the leaderboard and `test_private` for the final submission.\n",
    "As long as the `test_private.csv` data file is not released yet, the zip will contain only two files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B75zOG1F-KAQ",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1716808592027,
     "user": {
      "displayName": "Jonas Klesen",
      "userId": "16201315161566161330"
     },
     "user_tz": -120
    },
    "id": "B75zOG1F-KAQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13b5b570",
   "metadata": {
    "id": "13b5b570"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "340467b3",
   "metadata": {
    "id": "340467b3"
   },
   "source": [
    "### Appendix: Reminders about macro and micro averaging:\n",
    "\n",
    "When evaluating a classification model using `skm.classification_report(y_i, y_pred)` as done above, we get a macro and a weighted average.\n",
    "\n",
    "In the context of computing F1-score, \"macro\" and \"micro\" averaging are two commonly used techniques to aggregate the per-class F1-scores.\n",
    "\n",
    "**Micro-average**: Compute the F1-score globally by counting the total true positives, false negatives, and false positives over all classes, and then calculating precision, recall, and F1-score using these aggregated values.\n",
    "\n",
    "**Macro-average**: Calculate the F1-score for each class separately, and then take the average of these per-class F1-scores.\n",
    "\n",
    "The main difference between these two techniques is the way they treat class imbalance. Micro-average treats all classes equally, regardless of their size, while macro-average treats each class equally, regardless of the number of samples in that class.\n",
    "\n",
    "Micro-average is often used when we care about overall performance across all classes, and we want to give more weight to the performance on larger classes. In contrast, macro-average is often used when we want to evaluate the performance on each class separately and give equal weight to each class.\n",
    "\n",
    "\n",
    "In addition to micro and macro averaging, there is another common technique for computing the F1-score called **weighted averaging**.\n",
    "\n",
    "**Weighted averaging** is similar to macro averaging in that it computes the per-class F1-score and then takes the average of these scores. However, unlike macro averaging, weighted averaging takes into account the number of samples in each class when computing the average. Specifically, the weighted average is computed as follows:\n",
    "\n",
    "- Compute the F1-score for each class separately.\n",
    "- Compute the weight for each class as the number of samples in that class divided by the total number of samples.\n",
    "- Compute the weighted average of the per-class F1-scores, where each per-class F1-score is weighted by the weight of that class.\n",
    "\n",
    "The weighted average is commonly used when the dataset is imbalanced, meaning that some classes have many more samples than others. In such cases, using the simple average (macro-average) would give too much weight to the smaller classes, while using micro-average would give too much weight to the larger classes. The weighted average strikes a balance between these two approaches by giving more weight to the classes with more samples while still taking into account the performance of all classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82d2dc3",
   "metadata": {
    "id": "a82d2dc3"
   },
   "source": [
    "When computing the F1 score for the leaderboard and the final challenge results, we will be using the macro averaging strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8dd1b2",
   "metadata": {
    "id": "9b8dd1b2"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
